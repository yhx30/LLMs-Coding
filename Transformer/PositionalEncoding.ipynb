{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import exists\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.functional import log_softmax, pad\n",
    "import math\n",
    "import copy\n",
    "from copy import deepcopy\n",
    "import time\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "# from torchtext.data.functional import to_map_style_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "# from torchtext.vocab import build_vocab_from_iterator\n",
    "# import torchtext.datasets as datasets\n",
    "import spacy\n",
    "import GPUtil\n",
    "import warnings\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    '''\n",
    "    Implement the PE function.\n",
    "    d_model: è¾“å…¥åºåˆ—ä¸­æ¯ä¸ªè¯åµŒå…¥çš„ç»´åº¦ï¼ˆä¸è¯å‘é‡çš„ç»´åº¦ä¸€è‡´ï¼‰\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, d_model, dropout, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # compute the positional encoding once in log space.\n",
    "        # åˆå§‹åŒ–ä¸€ä¸ªå¤§å°ä¸º [max_len, d_model] çš„å…¨é›¶å¼ é‡ peï¼Œç”¨äºå­˜å‚¨ä½ç½®ç¼–ç çš„å€¼ã€‚\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        # torch.arange æ˜¯ PyTorch ä¸­ç”¨äºç”Ÿæˆç­‰é—´éš”æ•°å€¼åºåˆ—çš„ä¸€ç§å‡½æ•°ã€‚å…¶åŠŸèƒ½ç±»ä¼¼äº Python ä¸­çš„ range å‡½æ•°ï¼Œä½†å®ƒç”Ÿæˆçš„æ˜¯å¼ é‡ï¼ˆtensorï¼‰è€Œä¸æ˜¯æ™®é€šçš„æ•°å­—åºåˆ—ã€‚\n",
    "        # ç”Ÿæˆä¸€ä¸ª position å¼ é‡ï¼Œå®ƒçš„å€¼æ˜¯ä» 0 åˆ° max_len-1 çš„åºåˆ—ï¼ˆå³æ¯ä¸ªä½ç½®çš„ç´¢å¼•ï¼‰ï¼Œå½¢çŠ¶ä¸º [max_len, 1]ã€‚unsqueeze(1) è¡¨ç¤ºåœ¨ç¬¬ä¸€ç»´åº¦å¢åŠ ä¸€ä¸ªç»´åº¦ã€‚\n",
    "        position = torch.arange(0, max_len).unsqueeze(1) # [max_len, 1]\n",
    "        '''\n",
    "        è®¡ç®—ä½ç½®ç¼–ç ä¸­çš„åˆ†æ¯é¡¹ div_term, ä½¿ç”¨ä¸Šè¿°å…¬å¼, ä¿å­˜ä¸º div_term = 1/åˆ†æ¯ã€‚\n",
    "        torch.arange(0, d_model, 2) ç”Ÿæˆä» 0 å¼€å§‹åˆ° d_model-1 æ­¥é•¿ä¸º 2 çš„åºåˆ—ï¼Œè¿™éƒ¨åˆ†ç”¨æ¥å¤„ç†å¶æ•°ä½ç½®çš„ç»´åº¦ã€‚\n",
    "        \n",
    "        ä¸ºä»€ä¹ˆæ˜¯å…¬å¼: torch.arange(0, d_model, 2) * -(math.log(10000.0) / d_model) ?\n",
    "\n",
    "        '''\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, d_model, 2) * -(math.log(10000.0) / d_model)\n",
    "        )\n",
    "        pe[:, 0::2] = torch.sin(position * div_term) # (0, 2, 4, ...)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term) # (1, 3, 5, ...)\n",
    "        \n",
    "        # æ‰©å±•ç»´åº¦å¹¶æ³¨å†Œä¸º buffer\n",
    "        # ä½¿ç”¨ unsqueeze(0) ä¸ºä½ç½®ç¼–ç å¢åŠ ä¸€ä¸ªæ‰¹æ¬¡ç»´åº¦, è¿™æ ·å¯ä»¥é€‚é…ä¸åŒæ‰¹æ¬¡çš„æ•°æ®ã€‚\n",
    "        pe = pe.unsqueeze(0) # [max_len, d_model] -> [1, max_len, d_model]\n",
    "        \n",
    "        '''\n",
    "        å°† pe ä½œä¸º buffer æ³¨å†Œåˆ°æ¨¡å‹ä¸­ã€‚Buffer æ˜¯æ¨¡å‹çš„æŒä¹…çŠ¶æ€ï¼Œä½†ä¸ä¼šä½œä¸ºæ¨¡å‹å‚æ•°å‚ä¸ä¼˜åŒ–ï¼Œä¹Ÿä¸ä¼šéšç€æ¢¯åº¦æ›´æ–°è€Œæ”¹å˜ã€‚\n",
    "        é€šå¸¸æƒ…å†µä¸‹ï¼Œæ¨¡å‹ä¸­çš„çŠ¶æ€åˆ†ä¸ºä¸¤ç±»ï¼š\n",
    "            å¯è®­ç»ƒå‚æ•°ï¼šè¿™äº›å‚æ•°ä¼šåœ¨æ¨¡å‹çš„å‰å‘ä¼ æ’­å’Œåå‘ä¼ æ’­è¿‡ç¨‹ä¸­å‚ä¸æ¢¯åº¦è®¡ç®—ï¼Œå¹¶åœ¨ä¼˜åŒ–å™¨ä¸­æ›´æ–°ã€‚è¿™äº›å‚æ•°å¯ä»¥é€šè¿‡ nn.Parameter æ¥æ³¨å†Œï¼Œå®ƒä»¬é€šå¸¸æ˜¯æƒé‡æˆ–åç½®ã€‚é€šè¿‡ä¼˜åŒ–å™¨æˆ–æ‰‹åŠ¨è°ƒæ•´æ›´æ–°\n",
    "            éå¯è®­ç»ƒçš„æŒä¹…çŠ¶æ€ï¼šè¿™äº›æ˜¯æ¨¡å‹éœ€è¦çš„å€¼ï¼Œä½†å®ƒä»¬ä¸éœ€è¦å‚ä¸ä¼˜åŒ–è¿‡ç¨‹ã€‚åªèƒ½é€šè¿‡ä»£ç é€»è¾‘æ‰‹åŠ¨ä¿®æ”¹ã€‚ä¾‹å¦‚ï¼š \n",
    "                ç”¨äºå­˜å‚¨å›ºå®šçš„å¸¸é‡ï¼Œæ¯”å¦‚ç”¨äºæ­£åˆ™åŒ–çš„å‚æ•°ã€æ‰¹æ¬¡ç»Ÿè®¡æ•°æ®ï¼ˆå¦‚ BatchNorm ä¸­çš„å‡å€¼å’Œæ–¹å·®ï¼‰ã€‚\n",
    "                ç”¨äºæ¨¡å‹ä¸­ä¸éœ€è¦æ¢¯åº¦æ›´æ–°ä½†è¦éšæ¨¡å‹ä¸€èµ·ä¿å­˜çš„å˜é‡ã€‚\n",
    "        Buffer å°±å±äºç¬¬äºŒç±»çŠ¶æ€ã€‚å®ƒçš„å…³é”®ç‚¹æ˜¯ï¼š\n",
    "            ä¸ä¼šå‚ä¸æ¢¯åº¦è®¡ç®—ï¼Œä¸ä¼šéšç€è®­ç»ƒè¿‡ç¨‹ä¸­çš„ä¼˜åŒ–æ­¥éª¤è¢«æ›´æ–°ã€‚\n",
    "            ä¼šéšæ¨¡å‹ä¿å­˜å’ŒåŠ è½½ï¼Œå³ä½¿è¿™äº›å˜é‡ä¸ä¼šæ›´æ–°ï¼Œä»ç„¶å¸Œæœ›å®ƒä»¬ä½œä¸ºæ¨¡å‹çš„ä¸€éƒ¨åˆ†å­˜å‚¨å’Œæ¢å¤ã€‚\n",
    "        æŒä¹…å­˜å‚¨: pe æ˜¯ä¸€ä¸ªä½ç½®ç¼–ç çŸ©é˜µï¼Œä»£è¡¨äº†æ¯ä¸ªä½ç½®çš„ç¼–ç ã€‚è¿™ä¸ªçŸ©é˜µæ˜¯é¢„å…ˆè®¡ç®—çš„ï¼Œå¹¶ä¸”åœ¨æ•´ä¸ªæ¨¡å‹ä¸­ä¿æŒä¸å˜ï¼Œå› æ­¤å®ƒä¸éœ€è¦è¢«ä¼˜åŒ–å™¨æ›´æ–°ã€‚\n",
    "                ä½†åœ¨ä¿å­˜æ¨¡å‹æ—¶ï¼Œæˆ‘ä»¬å¸Œæœ›ä½ç½®ç¼–ç  pe å’Œå…¶ä»–å¯è®­ç»ƒçš„å‚æ•°ä¸€æ ·ï¼Œè¢«ä¿å­˜ä¸‹æ¥ï¼Œå¹¶åœ¨åŠ è½½æ¨¡å‹æ—¶æ¢å¤ã€‚\n",
    "        ä¸ä¼šæ›´æ–°ï¼šç”±äºä½ç½®ç¼–ç çš„çŸ©é˜µ pe æ˜¯åŸºäºå›ºå®šçš„å…¬å¼è®¡ç®—çš„ï¼Œå®ƒä¸éœ€è¦å‚ä¸åå‘ä¼ æ’­å’Œæ¢¯åº¦æ›´æ–°ã€‚\n",
    "                å› æ­¤ï¼Œå°†å…¶ä½œä¸º buffer æ¥æ³¨å†Œï¼Œè¿™æ ·åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å®ƒä¸ä¼šè¢«ä¼˜åŒ–å™¨é”™è¯¯åœ°ä¿®æ”¹ã€‚\n",
    "        '''\n",
    "         \n",
    "        self.register_buffer(\"pe\", pe)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x: [batch_size, sequence_length, d_model]\n",
    "        # è¿™ä¸€æ­¥æ˜¯å°†ä½ç½®ç¼–ç åŠ åˆ°è¯åµŒå…¥ä¸Šï¼Œä½¿å¾—æ¨¡å‹èƒ½å¤Ÿæ„ŸçŸ¥ä½ç½®ä¿¡æ¯ã€‚\n",
    "        # requires_grad_(False) æ˜¯ä¸ºäº†é˜²æ­¢ä½ç½®ç¼–ç å‚ä¸æ¢¯åº¦æ›´æ–°ï¼Œå› ä¸ºå®ƒä»¬æ˜¯å›ºå®šçš„ã€‚\n",
    "        x =  x + self.pe[:, x.size(1)].requires_grad_(False)\n",
    "        \n",
    "        '''\n",
    "        ä¸ºä»€ä¹ˆå¯¹ä½ç½®ç¼–ç åº”ç”¨ Dropout ? \n",
    "            å°½ç®¡ Dropout æœ€åˆæ˜¯åœ¨å…¨è¿æ¥å±‚ä¸­ç”¨äºâ€œéšæœºå¤±æ´»â€ä¸€éƒ¨åˆ†ç¥ç»å…ƒçš„ï¼Œä½†å®ƒçš„åº”ç”¨èŒƒå›´å®é™…ä¸Šæ›´å¹¿ï¼Œæ—¢å¯ä»¥ç”¨äºç¥ç»ç½‘ç»œçš„å„å±‚ã€æˆ–è¾“å‡ºå±‚ï¼Œä¹Ÿå¯ä»¥ç”¨äºç‰¹å¾å‘é‡ï¼Œå¦‚è¾“å…¥çš„è¯åµŒå…¥æˆ–ä½ç½®ç¼–ç ã€‚\n",
    "            å¢åŠ éšæœºæ€§: é€šè¿‡å¯¹ä½ç½®ç¼–ç çš„éƒ¨åˆ†å€¼è¿›è¡Œéšæœºâ€œå¤±æ´»â€ï¼Œå¯ä»¥å¼•å…¥ä¸€äº›éšæœºæ€§ï¼Œä½¿å¾—æ¨¡å‹ä¸ä¼šè¿‡åº¦ä¾èµ–ç‰¹å®šçš„ä½ç½®ä¿¡æ¯ã€‚è¿™å¯ä»¥è®©æ¨¡å‹åœ¨è®­ç»ƒæ—¶æ›´å…·é²æ£’æ€§ï¼Œå‡å°‘è¿‡æ‹Ÿåˆçš„å¯èƒ½ã€‚\n",
    "            æ­£åˆ™åŒ–è¾“å…¥: Dropout å¯ä»¥é˜²æ­¢æ¨¡å‹å¯¹ç‰¹å®šçš„è¾“å…¥ä½ç½®ç¼–ç äº§ç”Ÿè¿‡åº¦æ‹Ÿåˆã€‚å› ä¸ºä½ç½®ç¼–ç æ˜¯æ·»åŠ åˆ°è¾“å…¥ä¸­çš„ä¸€éƒ¨åˆ†ï¼Œ\n",
    "                      å¯¹å…¶è¿›è¡Œ dropout å¯ä»¥æœ‰æ•ˆåœ°æ‰“ç ´æ¨¡å‹å¯¹ç»å¯¹ä½ç½®ä¿¡æ¯çš„ä¾èµ–æ€§ï¼Œè¿«ä½¿æ¨¡å‹æ›´å…³æ³¨æ•´ä½“ä¸Šä¸‹æ–‡ï¼Œè€Œä¸ä»…ä»…æ˜¯æŸäº›ç‰¹å®šä½ç½®çš„ä¾èµ–ã€‚\n",
    "        '''\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Positional Encoding\n",
    "\n",
    "<img src=\"./images/Position.png\" alt=\"ç¤ºä¾‹å›¾ç‰‡\" width=\"700\">\n",
    "\n",
    "<img src=\"./images/Position2.png\" alt=\"ç¤ºä¾‹å›¾ç‰‡\" width=\"300\">\n",
    "\n",
    "$\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad PE_{(pos, 2i)} = \\sin(\\frac{pos}{10000^{\\frac{2i}{d_{model}}}})$\n",
    "\n",
    "$\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad PE_{(pos, 2i+1)} = \\cos(\\frac{pos}{10000^{\\frac{2i}{d_{model}}}})$\n",
    "\n",
    "$\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad$ å…¶ä¸­ 2i å’Œ 2i+1 æ˜¯ç‰¹å¾çš„ç»´åº¦ç¬¬å‡ ç»´ï¼Œåˆ†ä¸ºç¬¬**å¥‡**æ•°ç»´å’Œç¬¬**å¶**æ•°ç»´\n",
    "\n",
    "<img src=\"./images/Position3.png\" alt=\"ç¤ºä¾‹å›¾ç‰‡\" width=\"700\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ç»å¯¹ä½ç½®ç¼–ç "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  1.0000,  0.0000,  1.0000],\n",
       "        [ 0.8415,  0.5403,  0.0100,  1.0000],\n",
       "        [ 0.9093, -0.4161,  0.0200,  0.9998],\n",
       "        [ 0.1411, -0.9900,  0.0300,  0.9996],\n",
       "        [-0.7568, -0.6536,  0.0400,  0.9992],\n",
       "        [-0.9589,  0.2837,  0.0500,  0.9988],\n",
       "        [-0.2794,  0.9602,  0.0600,  0.9982],\n",
       "        [ 0.6570,  0.7539,  0.0699,  0.9976],\n",
       "        [ 0.9894, -0.1455,  0.0799,  0.9968],\n",
       "        [ 0.4121, -0.9111,  0.0899,  0.9960]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class SinPositionEncoding(nn.Module):\n",
    "    def __init__(self, max_sequence_length, d_model, base=10000):\n",
    "        super().__init__()\n",
    "        self.max_sequence_length = max_sequence_length\n",
    "        self.d_model = d_model\n",
    "        self.base = base\n",
    "        \n",
    "    def forward(self):\n",
    "        # åˆå§‹åŒ–ä¸€ä¸ªå¤§å°ä¸º [max_len, d_model] çš„å…¨é›¶å¼ é‡ peï¼Œç”¨äºå­˜å‚¨ä½ç½®ç¼–ç çš„å€¼ã€‚\n",
    "        pe = torch.zeros(self.max_sequence_length, self.d_model, dtype=torch.float)\n",
    "        \n",
    "        exp_1 = torch.arange(self.d_model//2, dtype=torch.float) # åˆå§‹åŒ–ä¸€åŠç»´åº¦ï¼Œsinä½ç½®ç¼–ç çš„ç»´åº¦è¢«åˆ†æˆäº†ä¸¤éƒ¨åˆ†\n",
    "        \n",
    "        exp_value = 2 * exp_1 / self.d_model\n",
    "        \n",
    "        alpha = 1 / (self.base ** exp_value) # size(d_model / 2)\n",
    "        \n",
    "        out = torch.arange(self.max_sequence_length, dtype=torch.float)[:, None] @ alpha[None, :] \n",
    "        # size(max_sequence_length, d_model / 2)\n",
    "        # [:, None] ç»™å¼ é‡æ–°æ·»åŠ äº†ä¸€ä¸ªç»´åº¦ (max_sequence_length, 1)\n",
    "        # [None, :] (1, d_model / 2)\n",
    "        # @: çŸ©é˜µä¹˜æ³•\n",
    "        \n",
    "        embedding_sin = torch.sin(out)\n",
    "        embedding_cos = torch.cos(out)\n",
    "        \n",
    "        pe[:, 0::2] = embedding_sin # å°† embedding_sin çš„å†…å®¹èµ‹å€¼åˆ° pe çš„å¶æ•°åˆ—ä¸Š\n",
    "        # è¡Œæ•° (max_sequence_length)ï¼šembedding_sin çš„è¡Œæ•°ä¸ pe ç›¸åŒï¼Œæ¯ä¸€è¡Œå¯¹åº”ä¸€ä¸ªä½ç½®ã€‚\n",
    "        # embedding_sin çš„åˆ—æ•°æ˜¯ pe çš„ä¸€åŠï¼Œå› ä¸ºæ­£å¼¦éƒ¨åˆ†åªå¡«å……åˆ° pe çš„å¶æ•°åˆ— (0::2)ã€‚\n",
    "        pe[:, 1::2] = embedding_cos\n",
    "        \n",
    "        return pe\n",
    "    \n",
    "SinPositionEncoding(d_model=4, max_sequence_length=10, base=10000).forward()\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# å¯å­¦ä¹ ä½ç½®ç¼–ç "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mn/8fw7vgd551394dxtykrf78200000gn/T/ipykernel_36378/3846723043.py:10: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
      "  nn.init.constant(pe.weight, 0.) # å°† pe.weight çš„æ‰€æœ‰å…ƒç´ åˆå§‹åŒ–ä¸º 0ã€‚\n"
     ]
    }
   ],
   "source": [
    "class TrainablePositionEncoding(nn.Module):\n",
    "    def __init__(self, max_sequence_length, d_model):\n",
    "        super().__init__()\n",
    "        self.max_sequence_length = max_sequence_length\n",
    "        self.d_model = d_model\n",
    "        \n",
    "    def forward(self):\n",
    "        pe = nn.Embedding(self.max_sequence_length, self.d_model)\n",
    "        # pe æ˜¯ä¸€ä¸ª torch.nn.Embedding æˆ–ç±»ä¼¼çš„å±‚ï¼Œå®ƒçš„ weight å±æ€§æ˜¯ä¸€ä¸ªå¯ä»¥å­¦ä¹ çš„æƒé‡çŸ©é˜µã€‚\n",
    "        nn.init.constant(pe.weight, 0.) # å°† pe.weight çš„æ‰€æœ‰å…ƒç´ åˆå§‹åŒ–ä¸º 0ã€‚\n",
    "        \n",
    "        return pe\n",
    "pe = TrainablePositionEncoding(max_sequence_length=10, d_model=4).forward()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ç›¸å¯¹ä½ç½®ç¼–ç \n",
    "\n",
    "<img src=\"./images/xiangdui.png\" alt=\"ç¤ºä¾‹å›¾ç‰‡\" width=\"1100\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RelativePosition(nn.Module):\n",
    "    '''\n",
    "    æ ¹æ®æŸ¥è¯¢å’Œé”®çš„é•¿åº¦ï¼Œç”Ÿæˆç›¸å¯¹ä½ç½®çš„å·®è·çŸ©é˜µã€‚\n",
    "    å°†å·®è·è£å‰ªåˆ°æŒ‡å®šèŒƒå›´å¹¶æ˜ å°„ä¸ºåˆæ³•ç´¢å¼•ã€‚\n",
    "    æ ¹æ®ç´¢å¼•ä»åµŒå…¥è¡¨ä¸­æŸ¥æ‰¾ç›¸åº”çš„åµŒå…¥ï¼Œè¾“å‡ºç›¸å¯¹ä½ç½®ç¼–ç ã€‚\n",
    "    '''\n",
    "    def __init__(self, num_units, max_relative_position, device = 'cpu'):\n",
    "        super().__init__()\n",
    "        self.num_units = num_units # æ¯ä¸ªç›¸å¯¹ä½ç½®çš„åµŒå…¥ç»´åº¦\n",
    "        self.max_relative_position = max_relative_position # æœ€å¤§ç›¸å¯¹è·ç¦»\n",
    "        self.embeddings_table = nn.Parameter(torch.Tensor(max_relative_position * 2 + 1, num_units))\n",
    "        # self.embeddings_table æ˜¯ä¸€ä¸ª learnable å‚æ•°çŸ©é˜µ, å½¢çŠ¶ä¸º (max_relative_position * 2 + 1, num_units)\n",
    "        # å¦‚æœ self.embeddings_table çš„å½¢çŠ¶æ˜¯ (5, num_units)ï¼Œ\n",
    "        # è€Œ final_mat æ˜¯ä¸€ä¸ªå½¢çŠ¶ä¸º (length_q, length_k) çš„å¼ é‡ï¼Œå…¶å€¼æ˜¯ [0, 1, 2, 3, 4] ä¹‹é—´çš„ç´¢å¼•ã€‚\n",
    "        # é‚£ä¹ˆ self.embeddings_table[final_mat] ä¼šè¿”å›å½¢çŠ¶ä¸º (length_q, length_k, num_units) çš„å¼ é‡ï¼Œå¯¹åº”æ¯ä¸ªç›¸å¯¹ä½ç½®çš„åµŒå…¥ã€‚\n",
    "\n",
    "        nn.init.xavier_uniform_(self.embeddings_table)\n",
    "        self.device = device\n",
    "        \n",
    "    def forward(self, length_q, length_k):\n",
    "        range_vec_q = torch.arange(length_q)\n",
    "        range_vec_k = torch.arange(length_k)\n",
    "        # ä¸€èˆ¬ length_q == length_k\n",
    "        # é€šè¿‡å¹¿æ’­æœºåˆ¶,è®¡ç®—ç›¸å¯¹ä½ç½®å·®çŸ©é˜µ, (length_q, length_k)\n",
    "        distance_mat = range_vec_q[None, :] - range_vec_k[:, None]\n",
    "        \n",
    "        # å°†è¶…å‡ºèŒƒå›´çš„å·®è·è£å‰ªåˆ° [-max_relative_position, max_relative_position]\n",
    "        distance_mat_clipped = torch.clamp(distance_mat, -self.max_relative_position, self.max_relative_position)\n",
    "        \n",
    "        # å°† [-2, -1, 0, 1, 2] æ˜ å°„ä¸º [0, 1, 2, 3, 4]\n",
    "        # final_mat æ˜¯ä¸€ä¸ªæ•´å‹ç´¢å¼•å¼ é‡ï¼Œç”¨äºä» self.embeddings_table ä¸­æŸ¥æ‰¾å¯¹åº”çš„åµŒå…¥\n",
    "        final_mat = distance_mat_clipped + self.max_relative_position\n",
    "        final_mat = torch.LongTensor(final_mat).to(self.device)\n",
    "        \n",
    "        embeddings = self.embeddings_table[final_mat].to(self.device)\n",
    "        \n",
    "        return embeddings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Head Attention\n",
    "\n",
    "<img src=\"./images/MultiHeadAttention.png\" alt=\"ç¤ºä¾‹å›¾ç‰‡\" width=\"700\">\n",
    "\n",
    "$MultiHead(Q, K, V) = Concat(head_1, head_2, ... , head_h)W^O\\text{, where }head_i = Attention(QW_i^Q, KW_i^K, VW_i^V)$\n",
    "\n",
    "$W_i^Q \\in \\mathbb{R}^{d_{model} \\times d_k}, \\quad W_i^K \\in \\mathbb{R}^{d_{model} \\times d_K}, \\quad W_i^V \\in \\mathbb{R}^{d_{model} \\times d_V}, \\quad W_i^O \\in \\mathbb{R}^{hd_v \\times d_{model}}$\n",
    "\n",
    "$$\n",
    "Attention(q, k, v) = [softmax(\\frac{q \\dot (k + pos_k)}{\\sqrt{d_k}})](v + pos_v)\n",
    "$$\n",
    "\n",
    "å…¶ä¸­ $pos_k$ æ˜¯æ³¨å…¥é”®ï¼ˆ$k$ï¼‰çš„ç›¸å¯¹ä½ç½®ç¼–ç ã€‚åªéœ€è¦ä¸º $k$ æ³¨å…¥ç›¸å¯¹ä½ç½®ä¿¡æ¯ï¼Œå› ä¸º ğ‘â‹…ğ‘˜ å·²èƒ½ä½“ç°æ³¨æ„åŠ›æƒé‡çš„ç›¸å¯¹é¡ºåºã€‚\n",
    "\n",
    "ç›¸å¯¹ä½ç½®ç¼–ç çš„æ ¸å¿ƒç›®æ ‡æ˜¯è°ƒæ•´é”®ï¼ˆkï¼‰å’Œå€¼ï¼ˆvï¼‰çš„æƒé‡ã€‚\n",
    "\n",
    "æ³¨å…¥åˆ° k ä¸­çš„ç›¸å¯¹ä½ç½®ç¼–ç å³å¯è¦†ç›–æ‰€æœ‰ä¿¡æ¯ï¼Œq ä¸éœ€è¦é‡å¤æ³¨å…¥ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_clones(module, num):\n",
    "        \"\"\"è¿”å›æŒ‡å®šæ•°é‡çš„ module æ·±æ‹·è´\"\"\"\n",
    "        return nn.ModuleList([deepcopy(module) for _ in range(num)])\n",
    "\n",
    "class RelativeMultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, dropout=0.1, batch_size=6, device='cpu'):\n",
    "        \"Take in model size and number of heads. \"\n",
    "        super(RelativeMultiHeadAttention, self).__init__()\n",
    "        self.device = device\n",
    "        self.d_model = d_model\n",
    "        self.n_heads = n_heads\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        assert d_model % n_heads == 0\n",
    "        self.head_dim = d_model // n_heads\n",
    "        \n",
    "        self.linears = _get_clones(nn.Linear(d_model, d_model), 4)\n",
    "        # linears: W_i^Q, W_i^K, W_i^V, W_i^O\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.relative_position_k = RelativePosition(self.head_dim, max_relative_position=16)\n",
    "        self.relative_position_v = RelativePosition(self.head_dim, max_relative_position=16)\n",
    "        # è¿”å›å½¢çŠ¶ä¸º (length_q, length_k, head_dim) çš„å¼ é‡ï¼Œå¯¹åº”æ¯ä¸ªç›¸å¯¹ä½ç½®çš„åµŒå…¥\n",
    "        \n",
    "        self.scale = torch.sqrt(torch.FloatTensor([self.head_dim])).to(device)\n",
    "        \n",
    "    def forward(self, query, key, value):\n",
    "        # embedding\n",
    "        # query, key, value = [batch_size, len, hid_dim]\n",
    "        # 1) Do all the linear projections in batch from d_model => h x d_k\n",
    "        '''\n",
    "        è¿™æ®µä»£ç çš„ä½œç”¨æ˜¯é€šè¿‡çº¿æ€§å˜æ¢ï¼Œå°† queryã€key å’Œ value æ˜ å°„åˆ°å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶çš„ç‰¹å¾ç©ºé—´ã€‚\n",
    "        .view(self.batch_size, -1, self.d_model):\n",
    "            .view(self.batch_size, -1, self.d_model)ï¼šå°†çº¿æ€§å˜æ¢çš„ç»“æœé‡å¡‘ä¸º (self.batch_size, -1, self.d_model) çš„å½¢çŠ¶ï¼Œ\n",
    "            ç›®çš„æ˜¯åˆ†é…ç»™æ¯ä¸ªå¤´ã€‚\n",
    "            view å‡½æ•°ç”¨äºæ”¹å˜å¼ é‡çš„å½¢çŠ¶ã€‚è¿™é‡Œçš„ç›®çš„æ˜¯å°†æ¯ä¸ªçº¿æ€§å±‚çš„è¾“å‡ºé‡å¡‘ä¸ºå½¢çŠ¶ä¸º [self.batch_size, -1, self.d_model] çš„å¼ é‡ã€‚\n",
    "            batch_size æ˜¯æ‰¹æ¬¡å¤§å°ï¼Œè¡¨ç¤ºæ¯ä¸ªæ‰¹æ¬¡ä¸­çš„æ ·æœ¬æ•°ã€‚\n",
    "            -1 æ˜¯è‡ªåŠ¨æ¨å¯¼çš„ç»´åº¦ï¼Œå®ƒä¼šæ ¹æ®åŸå§‹å¼ é‡çš„æ€»å…ƒç´ æ•°é‡å’ŒæŒ‡å®šçš„å…¶ä»–ç»´åº¦è‡ªåŠ¨è®¡ç®—,å³ lenã€‚\n",
    "            self.d_model æ˜¯ç‰¹å¾ç»´åº¦ã€‚\n",
    "        zip å‡½æ•°å°† self.linears å’Œ (query, key, value) è¿™ä¸‰ä¸ªå¼ é‡æ‰“åŒ…åœ¨ä¸€èµ·ï¼Œä½¿å¾—åœ¨å¾ªç¯ä¸­å¯ä»¥åŒæ—¶è¿­ä»£çº¿æ€§å±‚å’Œè¾“å…¥å¼ é‡ã€‚\n",
    "            ä¸‰ä¸ªçº¿æ€§å±‚, åˆ†åˆ«ä»¥query, key, valueä½œä¸ºå‚æ•°è·‘ä¸€é\n",
    "        '''\n",
    "        query, key, value = [l(x).view(self.batch_size, -1, self.d_model) for l,x in zip(self.linears, (query, key, value))]\n",
    "        \n",
    "        len_k = query.shape[1]\n",
    "        len_q = query.shape[1]\n",
    "        len_v = value.shape[1]\n",
    "        \n",
    "        # Self-Attention\n",
    "        # r_q1, r_k1 = [batch_size, len, n_heads, head_dim]\n",
    "        # -> [batch_size, n_heads, len, head_dim]\n",
    "        r_q1 = query.view(self.batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
    "        r_k1 = key.view(self.batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
    "        # -> [batch_size, n_heads, head_dim, len]\n",
    "        # è®¡ç®— q*k\n",
    "        attn1 = torch.matmul(r_q1, r_k1.permute(0, 1, 3, 2))\n",
    "        # attn1: [batch_size, n_heads, head_dim, len(_q), len(_k)]\n",
    "        \n",
    "        # [batch_size, len, d_model] -> [len, batch_size, d_model] (-> [len, batch_size, n_heads, head_dim])\n",
    "        # -> [len, batch_size * n_heads, head_dim]\n",
    "        # batch_size * n_heads åˆå¹¶æ‰¹é‡å¤§å°å’Œå¤´çš„æ•°é‡ï¼Œé€‚é…æ‰¹é‡åŒ–å¹¶è¡Œå¤„ç†\n",
    "        r_q2 = query.permute(1, 0, 2).contiguous().view(len_q, self.batch_size * self.n_heads, self.head_dim)\n",
    "        # contiguousçš„ä½œç”¨æ˜¯ ä¿è¯å¼ é‡åœ¨å†…å­˜ä¸­æ˜¯è¿ç»­å­˜å‚¨çš„ã€‚\n",
    "        # åœ¨æŸäº›å¼ é‡æ“ä½œï¼ˆæ¯”å¦‚ permute æˆ– viewï¼‰ä¹‹åï¼Œå¼ é‡å¯èƒ½ä¸å†æ˜¯è¿ç»­çš„ï¼Œ\n",
    "        # è¿™æ—¶éœ€è¦è°ƒç”¨ contiguous() æ¥åˆ›å»ºä¸€ä¸ªè¿ç»­çš„å¼ é‡å‰¯æœ¬ã€‚\n",
    "        # permute ä½œç”¨: æ”¹å˜å¼ é‡çš„ç»´åº¦é¡ºåºä»¥é€‚é…é€»è¾‘éœ€æ±‚ã€‚\n",
    "        # view ä½œç”¨: æ ¹æ®æ–°çš„éœ€æ±‚è°ƒæ•´å¼ é‡çš„å½¢çŠ¶ã€‚\n",
    "        # ä¸ºä»€ä¹ˆè¦å…ˆ permute å† viewï¼Ÿ\n",
    "        # å› ä¸º view è¦æ±‚å¼ é‡æ˜¯è¿ç»­çš„ï¼Œè€Œ permute ä¸æ”¹å˜å†…å­˜å¸ƒå±€ï¼Œå› æ­¤å¿…é¡»å…ˆ permuteï¼Œå†ç”¨ contiguous() ç¡®ä¿å†…å­˜è¿ç»­ï¼Œæœ€åç”¨ view è°ƒæ•´å½¢çŠ¶ã€‚\n",
    "        r_k2 = self.relative_position_k(len_q, len_k)\n",
    "        # r_k2: [len_q, len_k, head_dim]\n",
    "        \n",
    "        # è®¡ç®— q*pos_k\n",
    "        # [len, batch_size * n_heads, head_dim], [len_q, len_k, head_dim]->[len_q, head_dim, len_k]\n",
    "        # attn2: [len_q, batch_size * n_heads, len_k] -> [batch_size * n_heads, len_q, len_k]\n",
    "        attn2 = torch.matmul(r_q2, r_k2.transpose(1, 2)).transpose(0, 1)\n",
    "        attn2 = attn2.contiguous().view(self.batch_size, self.n_heads, len_q, len_k)\n",
    "        # attn2: [batch_size, n_heads, len_q, len_k]\n",
    "        \n",
    "        attn = (attn1 + attn2) / self.scale\n",
    "        attn = self.dropout(torch.softmax(attn, dim=-1))\n",
    "        # attn: [batch_size, n_heads, len(_q), len(_k)]\n",
    "        \n",
    "        # åŒä¸Š\n",
    "        r_v1 = value.view(self.batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
    "        # [batch_size, n_heads, head_dim, len]\n",
    "        \n",
    "        # è®¡ç®— attn*v\n",
    "        # [batch_size, n_heads, len(_q), len(_k)], [batch_size, n_heads, head_dim, len]\n",
    "        weight1 = torch.matmul(attn, r_v1)\n",
    "        # weight1: [batch_size, n_heads, len, len]\n",
    "        \n",
    "        r_v2 = self.relative_position_v(len_q, len_v)\n",
    "        # r_v2: [len_q, len_v, head_dim]\n",
    "        \n",
    "        # [batch_size, n_heads, len(_q), len(_k)] -> [len(_q), batch_size, n_heads, len(_k)]\n",
    "        # weight2 -> [len(_q), batch_size * n_heads, len(_k)]\n",
    "        weight2 = attn.permute(2, 0, 1, 3).contiguous().view(len_q, self.batch_size * self.n_heads, len_k) # len_k == len_v\n",
    "        # [len(_q), batch_size * n_heads, len(_k)], [len_q, len_v, head_dim]\n",
    "        # weight2 -> [len(_q), batch_size * n_heads, head_dim]\n",
    "        weight2 = torch.matmul(weight2, r_v2)\n",
    "        \n",
    "        # [len(_q), batch_size * n_heads, head_dim] (-> [batch_size * n_heads, len(_1), head_dim])\n",
    "        # weight2 -> [batch_size, n_heads, len(_q), head_dim]\n",
    "        weight2 = weight2.transpose(0, 1).contiguous().view(self.batch_size, self.n_heads, len_q, self.head_dim)\n",
    "        \n",
    "        # x: [batch_size, n_heads, len(_q), head_dim]\n",
    "        x = weight1 + weight2\n",
    "        \n",
    "        # x: [batch_size, len(_q), n_heads, head_dim]\n",
    "        x = x.permute(0, 2, 1, 3).contiguous()\n",
    "        \n",
    "        # x: [batch_size * len(_q), n_heads, head_dim] -> [batch_size * len(_q), d_model]\n",
    "        x = x.view(self.batch_size * len_q, self.d_model)\n",
    "        \n",
    "        return self.linears[-1](x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([10, 16])\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Hyperparameters\n",
    "    batch_size = 2\n",
    "    seq_len = 5\n",
    "    d_model = 16\n",
    "    n_heads = 4\n",
    "    device = 'cpu'\n",
    "\n",
    "    # Dummy inputs\n",
    "    query = torch.rand(batch_size, seq_len, d_model)\n",
    "    key = torch.rand(batch_size, seq_len, d_model)\n",
    "    value = torch.rand(batch_size, seq_len, d_model)\n",
    "\n",
    "    # Initialize the model\n",
    "    model = RelativeMultiHeadAttention(d_model=d_model, n_heads=n_heads, batch_size=batch_size, device=device)\n",
    "    model.to(device)\n",
    "    \n",
    "    # Forward pass\n",
    "    output = model(query, key, value)\n",
    "    print(\"Output shape:\", output.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RoPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sinusoidal_position_embedding(batch_size, nums_head, max_len, output_dim, device):\n",
    "    # (max_len, 1)\n",
    "    position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(-1)\n",
    "    # torch.arange ç”Ÿæˆä¸€ä¸ªå¼ é‡ï¼ˆtensorï¼‰ï¼Œè¯¥å¼ é‡åŒ…å«æŒ‡å®šèŒƒå›´å†…çš„è¿ç»­å€¼\n",
    "    # (output_dim // 2)\n",
    "    ids = torch.arange(0, output_dim // 2, dtype=torch.float) # å³å…¬å¼é‡Œçš„ i, içš„èŒƒå›´æ˜¯[0, d/2]\n",
    "    theta = torch.pow(10000, -2 * ids / output_dim)\n",
    "    # print(position.shape) # torch.Size([max_len, 1])\n",
    "    # print(theta.shape) # torch.Size([output_dim // 2])\n",
    "    \n",
    "    # (max_len, output_dim//2)\n",
    "    embeddings = position * theta # å³å…¬å¼é‡Œçš„: pos / (10000^(2i/d))\n",
    "    # print(embedding.shape) # torch.Size([max_len, output_dim//2])\n",
    "    \n",
    "    # torch.stack å°†ä¸€ç»„å¼ é‡æ²¿ç€æ–°çš„ç»´åº¦è¿›è¡Œè¿æ¥çš„å‡½æ•°ã€‚å®ƒå°†å¤šä¸ªå¼ é‡å †å åœ¨ä¸€èµ·ï¼Œè¿”å›ä¸€ä¸ªæ–°çš„å¼ é‡ï¼Œæ–°çš„ç»´åº¦é€šå¸¸æ˜¯å¢åŠ äº†ä¸€ä¸ªç»´åº¦çš„å¼ é‡ã€‚\n",
    "    # (max_len, output_dim//2, 2)\n",
    "    embeddings = torch.stack([torch.sin(embeddings), torch.cos(embeddings)], dim=-1)\n",
    "    \n",
    "    # torch.repeat(*sizes) sizesï¼šä¸€ä¸ªæ•´æ•°å…ƒç»„ï¼ŒæŒ‡å®šæ¯ä¸ªç»´åº¦çš„é‡å¤æ¬¡æ•°ã€‚è¿™ä¸ªå…ƒç»„çš„é•¿åº¦åº”è¯¥ä¸åŸå§‹å¼ é‡çš„ç»´åº¦æ•°ç›¸åŒã€‚\n",
    "    # e.g. t.repeat(2, 3) ä½¿å¾—åŸå§‹å¼ é‡åœ¨ç¬¬0ç»´ä¸Šé‡å¤äº† 2 æ¬¡ï¼Œåœ¨ç¬¬1ç»´ä¸Šé‡å¤äº† 3 æ¬¡\n",
    "    # (bs, head, max_len, output_dim//2, 2)\n",
    "    embeddings = embeddings.repeat(batch_size, nums_head, *([1] * len(embeddings.shape)))\n",
    "    # åœ¨ç¬¬ä¸€ç»´(bs)é‡å¤batch_sizeæ¬¡ï¼Œåœ¨ç¬¬äºŒç»´é‡å¤nums_headæ¬¡ï¼Œå…¶ä»–ç»´åº¦é‡å¤ä¸€æ¬¡(ä¸é‡å¤)\n",
    "    # *([1] * len(embeddings.shape)) åˆ›å»ºä¸€ä¸ªåˆ—è¡¨ï¼Œåˆ—è¡¨çš„é•¿åº¦ç­‰äº embeddings çš„ç»´åº¦æ•°(len(t.shape))ï¼Œæ¯ä¸ªå…ƒç´ éƒ½æ˜¯ 1\n",
    "    \n",
    "    # (hs, head, max_len, output_dim)\n",
    "    # reshapeåå°±æ˜¯å¶æ•°sinï¼Œå¥‡æ•°cosäº†ï¼ˆæ˜¯(output_dim//2, 2)ï¼Œç¬¬ä¸€åˆ—æ˜¯å¥‡ï¼Œç¬¬äºŒåˆ—æ˜¯å¶ï¼Œæ‰€ä»¥æŒ‰è¡Œæ‹¼æ¥å°±æ˜¯å¥‡å¶äº¤å‰ï¼‰\n",
    "    # å¦‚æœæ˜¯(2, output_dim//2)åˆ™å˜æˆäº†æ‰€æœ‰sinåœ¨å‰ï¼Œæ‰€æœ‰cosåœ¨å\n",
    "    '''\n",
    "    t = torch.tensor([[1, 3, 5], [2, 4, 6]])\n",
    "    flattened_tensor = t.reshape(-1) # tensor([1, 3, 5, 2, 4, 6])\n",
    "    flattened_tensor = t.T.reshape(-1) # tensor([1, 2, 3, 4, 5, 6])\n",
    "    t = torch.tensor([[[1, 2], [3, 4],[5,6]]])\n",
    "    flattened_tensor = t.reshape(-1) # tensor([1, 2, 3, 4, 5, 6])\n",
    "    flattened_tensor = t.T.reshape(-1) # tensor([1, 3, 5, 2, 4, 6])\n",
    "    '''\n",
    "    embeddings = torch.reshape(embeddings, (batch_size, nums_head, max_len, output_dim))\n",
    "    # print(embeddings.shape) # torch.Size([batch_size, nums_head, max_len, output_dim])\n",
    "    \n",
    "    embeddings = embeddings.to(device)\n",
    "    return embeddings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/RoPE.png\" alt=\"ç¤ºä¾‹å›¾ç‰‡\" width=\"1100\">\n",
    "\n",
    "$$\n",
    "f_q(x_m, m) = \n",
    "\\begin{pmatrix}\n",
    "\\cos m\\theta & -\\sin m\\theta \\\\\n",
    "\\sin m\\theta & \\cos m\\theta\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "W_q^{(1,1)} & W_q^{(1,2)} \\\\\n",
    "W_q^{(2,1)} & W_q^{(2,2)}\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "x_m^{(1)} \\\\\n",
    "x_m^{(2)}\n",
    "\\end{pmatrix}\n",
    "=\n",
    "\\begin{pmatrix}\n",
    "\\cos m\\theta & -\\sin m\\theta \\\\\n",
    "\\sin m\\theta & \\cos m\\theta\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "q_m^{(1)} \\\\\n",
    "q_m^{(2)}\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "For n-dim:\n",
    "$$\n",
    "f_q(x_m, m) = \n",
    "\\begin{pmatrix}\n",
    "\\cos m\\theta_0 & -\\sin m\\theta_0 & 0 & 0 & \\cdots & 0 & 0 \\\\\n",
    "\\sin m\\theta_0 & \\cos m\\theta_0 & 0 & 0 & \\cdots & 0 & 0 \\\\\n",
    "0 & 0 & \\cos m\\theta_1 & -\\sin m\\theta_1 & \\cdots & 0 & 0 \\\\\n",
    "0 & 0 & \\sin m\\theta_1 & \\cos m\\theta_1 & \\cdots & 0 & 0 \\\\\n",
    "\\vdots & \\vdots & \\vdots & \\vdots & \\ddots & \\vdots & \\vdots \\\\\n",
    "0 & 0 & 0 & 0 & \\cdots & \\cos m\\theta_{d/2-1} & -\\sin m\\theta_{d/2-1} \\\\\n",
    "0 & 0 & 0 & 0 & \\cdots & \\sin m\\theta_{d/2-1} & \\cos m\\theta_{d/2-1}\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "q_m^{(1)} \\\\\n",
    "q_m^{(2)} \\\\\n",
    "q_m^{(3)} \\\\\n",
    "q_m^{(4)} \\\\\n",
    "\\vdots\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "i.e.\n",
    "\n",
    "$$\n",
    "R_{\\Theta, m}^d \\mathbf{x} =\n",
    "\\begin{pmatrix}\n",
    "x_0 \\\\\n",
    "x_1 \\\\\n",
    "x_2 \\\\\n",
    "x_3 \\\\\n",
    "\\vdots \\\\\n",
    "x_{d-2} \\\\\n",
    "x_{d-1}\n",
    "\\end{pmatrix}\n",
    "\\otimes\n",
    "\\begin{pmatrix}\n",
    "\\cos m\\theta_0 \\\\\n",
    "\\cos m\\theta_0 \\\\\n",
    "\\cos m\\theta_1 \\\\\n",
    "\\cos m\\theta_1 \\\\\n",
    "\\vdots \\\\\n",
    "\\cos m\\theta_{d/2-1} \\\\\n",
    "\\cos m\\theta_{d/2-1}\n",
    "\\end{pmatrix}\n",
    "+\n",
    "\\begin{pmatrix}\n",
    "-x_1 \\\\\n",
    "x_0 \\\\\n",
    "-x_3 \\\\\n",
    "x_2 \\\\\n",
    "\\vdots \\\\\n",
    "-x_{d-1} \\\\\n",
    "x_{d-2}\n",
    "\\end{pmatrix}\n",
    "\\otimes\n",
    "\\begin{pmatrix}\n",
    "\\sin m\\theta_0 \\\\\n",
    "\\sin m\\theta_0 \\\\\n",
    "\\sin m\\theta_1 \\\\\n",
    "\\sin m\\theta_1 \\\\\n",
    "\\vdots \\\\\n",
    "\\sin m\\theta_{d/2-1} \\\\\n",
    "\\sin m\\theta_{d/2-1}\n",
    "\\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RoPE(q, k):\n",
    "    assert(q.shape == k.shape)\n",
    "    \n",
    "    # q, k: (bs, head, max_len, output_dim)\n",
    "    batch_size = q.shape[0]\n",
    "    nums_head = q.shape[1]\n",
    "    max_len = q.shape[2]\n",
    "    output_dim = q.shape[-1]\n",
    "    \n",
    "    # (bs, head, max_len, output_dim)\n",
    "    pos_emb = sinusoidal_position_embedding(batch_size, nums_head, max_len, output_dim, q.device)\n",
    "    \n",
    "    # cos_pos, sin_pos: (bs, head, max_len, output_dim)\n",
    "    # çœ‹ropeå…¬å¼å¯çŸ¥ï¼Œç›¸é‚»ä¸€ç»„(å¦‚1-2ï¼Œ3-4ï¼Œ5-6ï¼Œ...)ä¹‹é—´çš„ \\theta æ˜¯ç›¸åŒçš„ï¼Œæ‰€ä»¥cos(m\\theta)ï¼Œsin(m\\theta)ä¹Ÿæ˜¯åŒä¸€ä¸ªã€‚\n",
    "    # åªéœ€è¦å¤åˆ¶ä¸€ésinï¼Œcosçš„å‘é‡å³å¯,å¦‚(1, 2, 3)å˜æˆ(1, 1, 2, 2, 3, 3)\n",
    "    # interleave äº¤é”™\n",
    "    # torch.repeat_interleave(input, repeats, dim=None) æ¯ä¸ªå…ƒç´ é‡å¤ repeats æ¬¡\n",
    "    # pos_embä¸­å…ˆsinåcosäº¤é”™æ’åˆ—\n",
    "    sin_pos = pos_emb[..., 0::2].repeat_interleave(2, dim=-1)\n",
    "    cos_pos = pos_emb[..., 1::2].repeat_interleave(2, dim=-1)\n",
    "    \n",
    "    # q,k: (bs, head, max_len, output_dim)\n",
    "    q2 = torch.stack([-q[..., 1::2], q[..., 0::2]], dim=-1)\n",
    "    # q2: (bs, head, max_len, output_dim//2, 2)\n",
    "    q2 = q2.reshape(q.shape) # reshape åå°±æ˜¯æ­£è´Ÿäº¤æ›¿äº†ï¼Œå…ˆè´Ÿåæ­£ï¼Œå…ˆå¥‡åå¶ï¼Œå¥‡è´Ÿå¶æ­£\n",
    "    \n",
    "    # æ›´æ–°qw, *å¯¹åº”ä½ç½®æƒ³ä¹˜ï¼Œè§RoPEå…¬å¼\n",
    "    q = q * cos_pos + q2 * sin_pos\n",
    "    \n",
    "    # k åŒç†\n",
    "    k2 = torch.stack([-k[..., 1::2], k[..., 0::2]], dim=-1)\n",
    "    k2 = k2.reshape(k.shape)\n",
    "    k = k * cos_pos + k2 * sin_pos\n",
    "    \n",
    "    return q, k"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention\n",
    "\n",
    "<img src=\"./images/attention.png\" alt=\"ç¤ºä¾‹å›¾ç‰‡\" width=\"700\">\n",
    "\n",
    "$$\n",
    "Attention(Q, K, V) = softmax(\\frac{QK^\\top}{\\sqrt{d_k}})V\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention(q, k, v, mask=None, dropout=None, use_RoPE=True):\n",
    "    # q.shape: (bs, head, seq_len, dk)\n",
    "    # k.shape: (bs, head, seq_len, dk)\n",
    "    # v.shape: (bs, head, seq_len, dk)\n",
    "    \n",
    "    if use_RoPE:\n",
    "        q, k = RoPE(q, k)\n",
    "    \n",
    "    d_k = k.size()[-1]\n",
    "    \n",
    "    att_logits = torch.matmul(q, k.transpose(-2, -1)) # (bs, head, seq_len, seq_len)\n",
    "    att_logits /= math.sqrt(d_k)\n",
    "    \n",
    "    if mask is not None:\n",
    "        att_logits = att_logits.masked_fill(mask == 0, -1e9) # maskæ‰maskçŸ©é˜µä¸º0çš„éƒ¨åˆ†ï¼Œè®¾ä¸ºè´Ÿæ— ç©·å¤§\n",
    "    \n",
    "    att_scores = F.softmax(att_logits, dim=-1) # (bs, head, seq_ken, seq_len)\n",
    "    \n",
    "    if dropout is not None:\n",
    "        att_scores = dropout(att_scores)\n",
    "        \n",
    "    # (bs, head, seq_ken, seq_len) * (bs, head, seq_ken, dk) = (bs, head, seq_ken, seq_len)\n",
    "    \n",
    "    return torch.matmul(att_scores, v), att_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 12, 10, 32]) torch.Size([8, 12, 10, 10])\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # (bs, head, seq_ken, dk)\n",
    "    q = torch.randn((8, 12, 10, 32))\n",
    "    k = torch.randn((8, 12, 10, 32))\n",
    "    v = torch.randn((8, 12, 10, 32))\n",
    "    \n",
    "    res, att_scores = attention(q, k, v, mask=None, dropout=None, use_RoPE=True)\n",
    "    \n",
    "    # (bs, head, seq_len, seq_len), (bs, head, seq_len, seq_len)\n",
    "    print(res.shape, att_scores.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 4.7924e-01, -8.1184e-02,  5.0471e-01,  ...,  3.3904e-02,\n",
      "           -5.6309e-01, -6.9180e-01],\n",
      "          [ 2.8582e-02, -6.0121e-01,  2.2196e-01,  ...,  5.8244e-01,\n",
      "            4.9220e-02, -9.2528e-01],\n",
      "          [-5.4878e-01,  1.3189e-01, -8.0629e-01,  ...,  5.6292e-01,\n",
      "            4.6413e-01, -9.8989e-02],\n",
      "          ...,\n",
      "          [-9.2218e-02,  6.4448e-01, -8.5428e-02,  ..., -1.6412e-01,\n",
      "            1.2261e+00,  2.9948e-02],\n",
      "          [-3.7048e-01, -5.1464e-01, -3.4825e-02,  ...,  4.9220e-01,\n",
      "            2.7366e-01, -6.0428e-01],\n",
      "          [ 1.2036e-01, -3.5371e-01,  2.0824e-02,  ...,  8.7174e-01,\n",
      "           -4.2703e-01, -1.4617e-01]],\n",
      "\n",
      "         [[ 4.4240e-01,  2.7135e-01,  5.3776e-02,  ..., -4.9925e-01,\n",
      "           -5.0704e-01, -2.3714e-01],\n",
      "          [ 6.4617e-01, -1.4401e-03,  2.9460e-01,  ...,  4.6954e-01,\n",
      "            2.9533e-02,  3.1978e-01],\n",
      "          [ 1.3858e-01,  2.2991e-01, -3.6092e-02,  ...,  9.3772e-02,\n",
      "           -4.0733e-01,  1.0657e-01],\n",
      "          ...,\n",
      "          [ 3.4989e-02,  2.6000e-01,  1.4576e-01,  ...,  7.6645e-02,\n",
      "           -5.4252e-01, -3.2226e-01],\n",
      "          [ 8.8788e-02, -3.3115e-01,  4.2124e-01,  ...,  1.9108e-01,\n",
      "           -2.6256e-01,  1.8804e-01],\n",
      "          [-2.2684e-01, -3.4425e-02,  2.4380e-01,  ..., -2.5996e-02,\n",
      "           -4.0494e-01,  1.5631e-01]],\n",
      "\n",
      "         [[-2.1639e-01, -3.0787e-01,  2.8946e-01,  ...,  4.0077e-01,\n",
      "           -2.9228e-01,  1.3379e-01],\n",
      "          [-2.9024e-01, -2.3434e-01,  8.4954e-01,  ..., -1.5155e-01,\n",
      "           -5.4104e-02,  7.7297e-01],\n",
      "          [ 3.4037e-02, -9.1880e-01,  3.5744e-01,  ...,  6.9139e-01,\n",
      "           -5.7824e-01, -5.3555e-01],\n",
      "          ...,\n",
      "          [-5.1589e-02, -8.1027e-01,  6.0797e-01,  ...,  5.7539e-01,\n",
      "           -7.5569e-01, -4.5427e-01],\n",
      "          [-2.0580e-01, -7.4785e-02, -1.3232e-01,  ...,  2.2612e-01,\n",
      "           -3.0013e-01,  5.3096e-01],\n",
      "          [-2.7965e-01,  2.8699e-01,  4.1593e-03,  ..., -3.1512e-01,\n",
      "           -2.7426e-01,  1.8116e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.0195e-01, -2.3557e-01, -2.9131e-02,  ..., -5.4168e-01,\n",
      "            6.2999e-03, -1.0059e-01],\n",
      "          [ 2.8077e-01, -3.4883e-01,  4.2808e-01,  ...,  1.4548e-01,\n",
      "            1.0152e+00, -8.0355e-01],\n",
      "          [ 7.9329e-02,  6.6116e-01, -2.8568e-01,  ..., -1.6833e-01,\n",
      "            5.7640e-01,  3.5408e-01],\n",
      "          ...,\n",
      "          [ 4.3780e-01,  3.3121e-02,  1.6845e-01,  ..., -4.7117e-01,\n",
      "            2.4850e-01, -1.4400e-01],\n",
      "          [ 2.7887e-01,  3.1533e-01, -1.7673e-01,  ..., -4.8047e-01,\n",
      "            4.0018e-01,  2.9982e-02],\n",
      "          [ 1.2810e-01, -1.6127e-01,  1.0703e-01,  ..., -6.3268e-01,\n",
      "            3.6958e-01, -1.5425e-01]],\n",
      "\n",
      "         [[-4.7543e-01,  1.9812e-01,  5.6307e-01,  ...,  2.6627e-01,\n",
      "            4.0405e-01, -2.8978e-01],\n",
      "          [-2.4350e-01,  2.0318e-01,  2.7093e-01,  ...,  1.9905e-01,\n",
      "            2.2477e-01, -1.5909e-01],\n",
      "          [-1.6419e-01,  8.4131e-01,  1.8118e-02,  ..., -2.8050e-01,\n",
      "            2.2074e-01, -4.1729e-02],\n",
      "          ...,\n",
      "          [-1.7347e-01, -1.9314e-01,  5.1593e-01,  ...,  9.2244e-01,\n",
      "            4.7507e-01, -1.0857e+00],\n",
      "          [-3.5580e-01, -1.7366e-01,  8.5489e-01,  ...,  8.3374e-02,\n",
      "            1.0673e+00, -6.1902e-01],\n",
      "          [-5.0193e-01, -1.7296e-01,  5.5527e-01,  ..., -8.7066e-02,\n",
      "           -8.0513e-02,  3.3487e-01]],\n",
      "\n",
      "         [[-4.5692e-01, -6.4109e-01,  4.4119e-01,  ...,  2.5906e-01,\n",
      "           -5.8484e-01,  4.4600e-01],\n",
      "          [-2.8324e-01, -8.1902e-01,  7.3462e-01,  ...,  1.3290e-01,\n",
      "           -5.7838e-02, -7.8076e-02],\n",
      "          [ 1.2106e-01, -1.0992e+00,  6.4203e-01,  ..., -4.2581e-01,\n",
      "           -1.1977e-01,  1.1300e-01],\n",
      "          ...,\n",
      "          [-2.7591e-01, -8.1999e-01,  4.2743e-01,  ...,  2.0346e-01,\n",
      "           -4.7837e-01,  3.6752e-01],\n",
      "          [-3.2803e-01, -4.4243e-01,  2.4399e-01,  ...,  1.6217e-01,\n",
      "           -1.0442e-02,  5.1314e-02],\n",
      "          [ 6.6155e-03, -8.9396e-01,  3.4566e-01,  ..., -3.1655e-01,\n",
      "            4.0352e-02,  6.4501e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.7029e-01,  1.7544e-01, -8.1281e-04,  ..., -2.6750e-02,\n",
      "            2.2090e-01, -2.5004e-01],\n",
      "          [ 5.4162e-01,  9.7657e-01,  4.3832e-01,  ..., -8.4969e-01,\n",
      "            3.1121e-01,  3.7905e-01],\n",
      "          [-3.9632e-01,  2.7898e-01, -3.2684e-01,  ...,  5.6299e-01,\n",
      "            1.2080e-01, -4.8805e-01],\n",
      "          ...,\n",
      "          [-2.7699e-01,  8.4262e-02,  6.2049e-02,  ...,  2.8001e-01,\n",
      "            6.7081e-02,  8.2519e-03],\n",
      "          [-4.4701e-02,  4.6291e-01, -3.8571e-02,  ...,  2.4390e-01,\n",
      "            2.0752e-02, -1.6943e-02],\n",
      "          [ 1.3064e-01,  3.8652e-01, -1.7360e-01,  ...,  1.1950e-01,\n",
      "           -4.7680e-01,  2.3712e-01]],\n",
      "\n",
      "         [[ 5.8091e-01, -5.3749e-01, -2.0376e-01,  ..., -9.8394e-01,\n",
      "           -3.8998e-01, -5.2257e-01],\n",
      "          [ 6.0920e-01, -1.8986e-01,  9.0336e-01,  ..., -5.9936e-01,\n",
      "            2.9605e-01, -2.7062e-01],\n",
      "          [ 3.1753e-01, -2.7817e-01,  2.1399e-01,  ..., -1.3096e+00,\n",
      "            1.1912e-02, -3.8203e-01],\n",
      "          ...,\n",
      "          [-2.3240e-01, -6.0973e-01, -1.7615e-01,  ..., -1.8782e+00,\n",
      "           -4.0190e-01, -8.0506e-01],\n",
      "          [ 4.7885e-01,  1.9562e-02, -6.3807e-02,  ..., -1.0138e+00,\n",
      "            3.8124e-01, -1.4419e-01],\n",
      "          [ 8.5594e-01, -1.5613e-01, -1.8509e-01,  ..., -2.5674e-01,\n",
      "            3.6647e-01, -2.9472e-01]],\n",
      "\n",
      "         [[ 9.2285e-02,  1.5553e-01,  1.0490e-01,  ...,  5.6417e-01,\n",
      "            4.8751e-01, -1.3544e-01],\n",
      "          [ 3.2645e-01, -4.1026e-02, -9.7962e-02,  ...,  3.8279e-01,\n",
      "            1.8368e-01, -1.1838e-01],\n",
      "          [ 5.7203e-01,  4.8235e-01,  1.9791e-01,  ..., -3.6352e-02,\n",
      "            5.8256e-02, -4.0499e-01],\n",
      "          ...,\n",
      "          [ 3.9179e-01,  3.0344e-01,  1.4551e-01,  ...,  3.6985e-01,\n",
      "           -1.9181e-01, -4.0508e-01],\n",
      "          [ 8.6369e-02,  7.5198e-01,  1.3808e-01,  ...,  5.1065e-01,\n",
      "           -8.2306e-02, -2.9161e-01],\n",
      "          [ 4.0088e-01, -1.6916e-01,  8.7512e-02,  ...,  6.3094e-01,\n",
      "            6.3393e-01, -4.5854e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.6879e-02, -1.3068e-01,  8.2993e-01,  ..., -2.3318e-01,\n",
      "           -8.1337e-03,  5.9286e-01],\n",
      "          [ 4.1407e-02, -2.1275e-01,  8.5471e-01,  ...,  8.2760e-02,\n",
      "            1.9359e-01,  6.2116e-01],\n",
      "          [-1.8419e-01, -9.3145e-02,  5.8710e-01,  ..., -2.1494e-01,\n",
      "           -1.7035e-02,  4.5434e-01],\n",
      "          ...,\n",
      "          [-6.4694e-01, -4.9237e-01,  5.0846e-01,  ..., -4.3289e-01,\n",
      "            6.9534e-01,  1.0738e-01],\n",
      "          [-2.6657e-01, -2.6750e-01,  7.0937e-01,  ..., -3.1482e-01,\n",
      "            1.7169e-01,  5.8019e-01],\n",
      "          [-1.7186e-01,  6.1341e-02,  5.5129e-01,  ..., -4.6578e-01,\n",
      "           -2.2503e-01,  3.4128e-01]],\n",
      "\n",
      "         [[ 9.7067e-01,  6.6213e-03, -2.3060e-01,  ...,  4.1603e-01,\n",
      "            3.8044e-01, -1.0995e-01],\n",
      "          [ 1.0522e+00,  4.9822e-01, -3.6363e-01,  ...,  2.3937e-01,\n",
      "            1.9121e-01,  7.1644e-02],\n",
      "          [ 1.7395e-01,  4.5694e-01,  2.0278e-01,  ...,  5.9748e-01,\n",
      "            1.3978e-01,  5.8743e-02],\n",
      "          ...,\n",
      "          [ 6.3406e-01,  2.8487e-01, -3.4488e-01,  ..., -2.6943e-01,\n",
      "            1.8932e-01, -3.0720e-01],\n",
      "          [ 3.5947e-01,  4.4615e-01,  3.7505e-01,  ...,  3.5900e-01,\n",
      "            1.1405e-01,  3.6689e-01],\n",
      "          [ 4.7173e-01,  6.4534e-01, -7.9822e-02,  ...,  5.0651e-02,\n",
      "            3.7713e-01, -3.6410e-01]],\n",
      "\n",
      "         [[-4.3475e-02,  1.1449e-01,  2.4829e-01,  ...,  5.5120e-01,\n",
      "           -4.5483e-01,  2.9874e-01],\n",
      "          [ 2.6935e-01,  3.3060e-01,  1.5657e-01,  ..., -2.5308e-01,\n",
      "           -5.6907e-01, -4.6733e-01],\n",
      "          [-2.1354e-02,  4.8800e-01, -7.4036e-01,  ...,  6.2789e-01,\n",
      "           -6.1856e-01, -2.2941e-01],\n",
      "          ...,\n",
      "          [ 2.1814e-02,  4.1347e-01, -3.6688e-01,  ...,  2.7987e-01,\n",
      "           -4.0039e-01, -3.0427e-01],\n",
      "          [ 7.8844e-02, -1.7686e-01,  4.2960e-01,  ...,  9.4490e-01,\n",
      "           -3.9176e-01,  8.3883e-02],\n",
      "          [ 1.1996e-01,  1.3163e-01, -2.0352e-01,  ..., -7.3182e-02,\n",
      "           -1.8716e-01, -4.9470e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3243e+00, -1.9121e-01,  1.7316e-01,  ...,  7.7150e-01,\n",
      "           -1.7175e-01,  2.6716e-01],\n",
      "          [ 5.4124e-01,  9.5806e-02,  1.6171e-01,  ...,  9.1571e-01,\n",
      "           -1.1631e-01,  3.6933e-01],\n",
      "          [ 3.7376e-01, -3.0432e-01,  2.4725e-01,  ...,  9.2877e-01,\n",
      "            5.7641e-02, -8.4606e-02],\n",
      "          ...,\n",
      "          [ 1.0740e+00,  2.0798e-01,  8.3930e-01,  ...,  8.4779e-01,\n",
      "           -4.2792e-01, -1.4105e-02],\n",
      "          [ 7.6515e-01,  1.3741e-01,  1.2855e-01,  ...,  3.9787e-01,\n",
      "           -1.7103e-01, -1.0558e-01],\n",
      "          [ 6.2873e-01,  3.7529e-01,  4.9916e-01,  ...,  8.6743e-01,\n",
      "           -1.1591e-01, -1.5042e-01]],\n",
      "\n",
      "         [[ 2.2594e-01,  4.9842e-01,  3.0417e-02,  ...,  1.8655e-02,\n",
      "           -1.1960e-01,  2.9537e-01],\n",
      "          [ 5.5913e-02,  5.9855e-01,  4.2994e-01,  ..., -1.9249e-02,\n",
      "           -1.3079e-01, -3.2250e-02],\n",
      "          [-6.9349e-02,  4.1468e-01,  7.3211e-01,  ..., -1.1942e-01,\n",
      "           -1.5448e-01, -5.6684e-02],\n",
      "          ...,\n",
      "          [-1.9243e-01,  7.6134e-01, -4.1016e-02,  ..., -1.9849e-01,\n",
      "           -8.0432e-01, -3.1233e-01],\n",
      "          [-1.1551e-01,  4.3944e-01,  1.3607e-01,  ..., -6.2944e-02,\n",
      "           -2.5979e-01, -2.8764e-02],\n",
      "          [-2.1726e-01,  5.1984e-01, -7.4972e-03,  ..., -1.0121e-01,\n",
      "           -5.6147e-01, -1.8461e-01]],\n",
      "\n",
      "         [[ 4.5489e-01, -3.4948e-01,  5.3839e-01,  ...,  1.1812e-01,\n",
      "            8.2117e-02,  1.7124e-01],\n",
      "          [ 8.3414e-01, -3.3398e-01,  7.3370e-02,  ..., -3.9293e-01,\n",
      "           -2.5024e-01,  4.6656e-02],\n",
      "          [-2.7639e-02,  1.4252e-01, -8.5912e-02,  ..., -1.9518e-02,\n",
      "           -2.3589e-02,  2.8576e-01],\n",
      "          ...,\n",
      "          [ 5.5886e-01,  5.0275e-01, -9.9409e-02,  ..., -1.4107e-01,\n",
      "           -1.3549e-01,  1.3512e-01],\n",
      "          [ 3.6913e-01, -4.2027e-01,  7.3338e-01,  ...,  8.2184e-02,\n",
      "            3.0860e-01,  1.9023e-01],\n",
      "          [ 7.9675e-01, -2.7875e-01,  4.3588e-01,  ..., -1.0544e-01,\n",
      "           -1.7917e-02, -1.9584e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.9295e-02,  2.0494e-01, -4.7975e-03,  ..., -4.9044e-01,\n",
      "           -2.7083e-01,  2.4271e-02],\n",
      "          [ 1.2941e-02, -2.6700e-01, -1.5023e-01,  ...,  2.3695e-01,\n",
      "           -1.4488e-01,  4.4903e-01],\n",
      "          [-3.0651e-01,  1.8228e-01, -6.0365e-02,  ..., -4.4616e-01,\n",
      "            3.2392e-01,  7.6669e-02],\n",
      "          ...,\n",
      "          [-2.2396e-01,  1.0517e-01, -2.2325e-01,  ..., -3.3939e-02,\n",
      "            2.4434e-02,  3.0712e-01],\n",
      "          [-9.3771e-01,  8.5500e-01, -7.2919e-01,  ..., -6.4170e-01,\n",
      "            9.1899e-01,  4.2282e-01],\n",
      "          [ 4.6549e-01, -8.4375e-02,  2.3884e-01,  ..., -1.0444e-01,\n",
      "           -7.9816e-01,  5.8314e-01]],\n",
      "\n",
      "         [[-1.3256e-01,  5.9601e-01, -1.3535e-01,  ...,  1.0708e+00,\n",
      "           -3.4130e-01,  5.8796e-01],\n",
      "          [-4.0031e-01,  2.2137e-01,  2.7294e-01,  ..., -8.3012e-02,\n",
      "           -3.0582e-01,  8.4462e-01],\n",
      "          [-2.9746e-01,  1.9875e-02,  3.2362e-01,  ...,  5.8164e-01,\n",
      "           -3.8398e-01,  1.2948e+00],\n",
      "          ...,\n",
      "          [-6.8934e-01,  4.0069e-01,  5.2332e-01,  ...,  4.7779e-01,\n",
      "           -8.9600e-01,  4.7081e-01],\n",
      "          [-5.7948e-01,  3.0864e-01,  7.0143e-01,  ...,  2.0274e-01,\n",
      "           -6.4357e-01,  4.4949e-01],\n",
      "          [-6.4063e-01,  2.7403e-01,  3.7135e-01,  ..., -6.0648e-03,\n",
      "           -5.4945e-01,  6.9397e-01]],\n",
      "\n",
      "         [[ 8.1531e-02, -8.0417e-02,  6.1975e-02,  ..., -3.5764e-01,\n",
      "            5.6226e-01,  3.6915e-01],\n",
      "          [-6.1186e-01,  1.9519e-01,  4.0820e-01,  ..., -6.5346e-01,\n",
      "            4.1650e-01, -5.0919e-01],\n",
      "          [-6.0355e-01, -6.4829e-02,  2.6066e-01,  ..., -6.0753e-01,\n",
      "            4.1690e-01, -1.0619e-01],\n",
      "          ...,\n",
      "          [-5.7858e-01, -1.0667e-01,  3.5084e-01,  ..., -6.5580e-01,\n",
      "            5.3641e-01, -2.2045e-01],\n",
      "          [-4.4036e-01,  2.0049e-01, -5.2761e-01,  ..., -4.6803e-01,\n",
      "            2.9812e-01, -4.4919e-03],\n",
      "          [ 9.1632e-02, -1.5355e-01,  2.4623e-01,  ..., -5.8234e-01,\n",
      "            6.4249e-01,  2.1948e-01]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 3.4793e-01, -2.9164e-01,  1.1798e-01,  ...,  2.3959e-01,\n",
      "            8.7365e-02, -1.8304e-01],\n",
      "          [ 7.1551e-02, -4.0548e-01,  2.0729e-01,  ..., -4.6791e-01,\n",
      "            3.5786e-01,  1.8609e-01],\n",
      "          [-2.3844e-01, -2.2511e-01,  4.1091e-01,  ...,  4.5862e-01,\n",
      "            1.8404e-01,  7.5979e-02],\n",
      "          ...,\n",
      "          [-1.1000e-01, -5.7740e-01,  3.3437e-01,  ..., -5.4834e-01,\n",
      "            5.0374e-01, -5.7071e-01],\n",
      "          [-2.5750e-02, -5.2174e-01,  2.5303e-01,  ..., -2.3786e-01,\n",
      "            4.7181e-01, -5.1656e-01],\n",
      "          [ 3.9212e-01, -2.2885e-01,  1.5712e-01,  ...,  3.0947e-01,\n",
      "            3.4574e-01, -5.2711e-02]],\n",
      "\n",
      "         [[ 4.2538e-01,  4.5353e-01,  1.2700e-01,  ..., -3.8070e-01,\n",
      "           -1.0039e-01,  1.3760e-02],\n",
      "          [ 7.3353e-02,  1.6065e-01,  3.8837e-02,  ..., -1.6612e-01,\n",
      "            3.2539e-01, -2.6115e-01],\n",
      "          [ 1.3307e-01,  3.6230e-01,  3.5560e-01,  ..., -2.0223e-01,\n",
      "           -5.4144e-02, -5.9702e-01],\n",
      "          ...,\n",
      "          [ 3.3271e-01,  2.7384e-01,  9.1058e-01,  ..., -6.8907e-01,\n",
      "            1.9202e-01, -1.9739e-01],\n",
      "          [ 6.7893e-02,  3.8260e-01,  5.2463e-01,  ..., -1.6778e-01,\n",
      "            3.1047e-01, -1.6127e-01],\n",
      "          [ 2.0472e-01,  4.2271e-01, -3.6884e-02,  ...,  1.7339e-01,\n",
      "            6.1886e-01, -2.5198e-01]],\n",
      "\n",
      "         [[-2.6201e-02,  4.2892e-02, -1.2884e-01,  ..., -4.8532e-01,\n",
      "            3.8394e-01, -7.0707e-01],\n",
      "          [ 4.9076e-01,  8.4691e-01,  2.6701e-01,  ..., -8.8749e-01,\n",
      "            6.8527e-01, -3.2109e-02],\n",
      "          [ 1.7296e-01,  7.4011e-01, -4.3412e-01,  ..., -5.6196e-01,\n",
      "           -1.5765e-01,  2.9952e-01],\n",
      "          ...,\n",
      "          [ 1.7058e-01, -6.1463e-01, -4.6562e-01,  ...,  3.5287e-01,\n",
      "           -6.6381e-01, -1.7147e-01],\n",
      "          [-7.7515e-01,  2.2416e-01, -1.2662e-02,  ...,  6.4468e-01,\n",
      "           -2.5655e-01,  2.2389e-01],\n",
      "          [ 2.8420e-01,  3.1885e-01,  1.7346e-01,  ..., -4.2993e-01,\n",
      "            2.9269e-01, -2.4433e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.4071e-01, -2.7825e-01,  1.3341e-01,  ...,  2.9251e-01,\n",
      "            7.1916e-01,  3.1884e-02],\n",
      "          [ 2.4261e-01,  5.5601e-01, -3.7778e-01,  ..., -4.3500e-03,\n",
      "            1.0315e+00, -2.3222e-01],\n",
      "          [-3.3044e-01, -4.0753e-01,  2.9208e-01,  ...,  5.2939e-03,\n",
      "            1.6210e+00,  3.9556e-01],\n",
      "          ...,\n",
      "          [-7.2248e-02,  3.9507e-01, -2.2531e-01,  ..., -7.6233e-02,\n",
      "           -5.4306e-02,  2.9579e-01],\n",
      "          [ 4.5611e-01, -3.0219e-01,  3.3346e-01,  ...,  7.2762e-01,\n",
      "            5.7999e-01,  2.8652e-01],\n",
      "          [-9.9513e-01, -4.1706e-01,  1.6258e-01,  ...,  2.6462e-01,\n",
      "            5.4178e-01,  1.0018e-01]],\n",
      "\n",
      "         [[ 3.9263e-01, -8.4098e-01, -1.8766e-01,  ...,  3.2654e-01,\n",
      "            2.3071e-01,  3.6736e-01],\n",
      "          [-3.6515e-01, -6.6667e-01, -2.0525e-01,  ..., -8.2563e-02,\n",
      "            2.0923e-01,  1.3242e-01],\n",
      "          [ 2.6366e-01, -7.3263e-01, -6.0818e-04,  ...,  1.3993e-01,\n",
      "            4.3431e-01,  4.8702e-01],\n",
      "          ...,\n",
      "          [ 3.7649e-01, -8.9890e-01, -6.5742e-02,  ..., -9.9849e-01,\n",
      "            1.2734e-01,  3.3203e-01],\n",
      "          [ 2.9385e-01, -8.0958e-01,  1.0681e-01,  ...,  2.4611e-01,\n",
      "            1.5585e-01,  4.7888e-01],\n",
      "          [-1.9156e-01, -4.8420e-01, -5.3325e-01,  ..., -1.3070e+00,\n",
      "            2.4056e-01,  3.3837e-01]],\n",
      "\n",
      "         [[ 8.9472e-01,  7.3788e-01,  5.4692e-01,  ...,  2.0574e-01,\n",
      "           -1.8933e-02,  2.0512e-01],\n",
      "          [ 4.2799e-01, -2.4217e-01, -2.6678e-01,  ...,  3.7725e-01,\n",
      "           -1.9129e-01,  7.7682e-01],\n",
      "          [ 5.1894e-03,  2.7766e-01, -1.8488e-01,  ...,  3.3199e-01,\n",
      "            3.0357e-01,  7.1835e-01],\n",
      "          ...,\n",
      "          [ 5.7355e-02, -4.6527e-01, -3.3178e-01,  ...,  4.0403e-01,\n",
      "           -4.8888e-01,  6.8698e-01],\n",
      "          [ 7.7599e-01,  3.1980e-01,  3.0325e-01,  ...,  2.6604e-01,\n",
      "           -2.4436e-01,  4.6815e-01],\n",
      "          [ 8.2133e-01, -1.7685e-02, -3.6779e-01,  ...,  1.0833e-01,\n",
      "           -9.4827e-02,  7.4480e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6109e-01,  3.8316e-01, -3.5317e-01,  ...,  1.3212e-01,\n",
      "           -2.0413e-01, -2.4374e-01],\n",
      "          [-8.9549e-02,  5.0399e-01, -6.5639e-01,  ...,  5.2028e-01,\n",
      "           -4.8563e-01, -2.1895e-01],\n",
      "          [ 1.6616e-01, -4.1562e-01, -4.0586e-01,  ...,  2.8994e-01,\n",
      "            2.1557e-01,  1.2789e-01],\n",
      "          ...,\n",
      "          [-4.1460e-01, -8.5589e-01, -4.6663e-01,  ...,  3.0978e-01,\n",
      "            3.9882e-01,  2.2555e-01],\n",
      "          [ 2.9411e-01,  1.7158e-01, -5.0183e-02,  ..., -1.3152e-01,\n",
      "           -6.4166e-03, -1.8002e-01],\n",
      "          [ 3.0146e-02, -6.4981e-01, -6.4923e-01,  ...,  4.3632e-01,\n",
      "            1.6933e-01,  7.3136e-02]],\n",
      "\n",
      "         [[-1.5327e-01, -2.7182e-01,  3.1793e-01,  ...,  3.7502e-01,\n",
      "            3.9386e-01,  6.2427e-01],\n",
      "          [ 1.1513e-01, -5.6229e-01,  1.7839e-01,  ...,  5.2734e-01,\n",
      "            2.5943e-01, -9.9544e-02],\n",
      "          [-1.0602e-01, -2.3308e-01,  2.2594e-01,  ...,  4.7585e-01,\n",
      "            4.0451e-01, -8.0822e-02],\n",
      "          ...,\n",
      "          [ 2.0647e-01, -6.0084e-01,  3.4130e-01,  ...,  5.8837e-01,\n",
      "            2.8919e-01, -2.9388e-01],\n",
      "          [ 3.5841e-01, -1.1047e+00,  1.6670e-01,  ...,  5.3994e-01,\n",
      "            1.8940e-01,  3.8007e-01],\n",
      "          [-4.5000e-01, -2.4313e-01,  1.6802e-01,  ...,  2.9690e-01,\n",
      "            7.6262e-01,  5.7498e-01]],\n",
      "\n",
      "         [[ 2.4948e-01,  1.7732e-01,  5.6860e-01,  ..., -3.4419e-01,\n",
      "            2.3950e-01, -1.0063e+00],\n",
      "          [ 9.1258e-01, -2.6015e-01,  4.5902e-01,  ...,  2.9973e-01,\n",
      "            4.4914e-01, -9.3596e-01],\n",
      "          [-9.8624e-02,  7.6542e-01,  5.7637e-01,  ..., -2.7896e-02,\n",
      "            1.6406e-01, -1.3386e+00],\n",
      "          ...,\n",
      "          [ 6.6470e-02,  5.6028e-01,  5.6362e-01,  ..., -2.5880e-01,\n",
      "           -4.5017e-01, -1.0596e+00],\n",
      "          [ 3.0611e-01, -1.2370e-02,  5.5587e-01,  ..., -4.1938e-01,\n",
      "           -2.0176e-01, -7.5091e-01],\n",
      "          [ 1.7629e-01,  8.2877e-02,  3.5683e-01,  ..., -5.4968e-02,\n",
      "            4.3594e-01, -9.3648e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-8.1328e-01, -7.7880e-03, -5.7301e-01,  ..., -2.3938e-01,\n",
      "           -1.1993e-01,  2.2179e-01],\n",
      "          [-1.0713e+00, -1.8561e-01, -1.4299e-01,  ...,  3.4184e-01,\n",
      "           -7.9613e-01,  5.1186e-01],\n",
      "          [-4.8969e-01, -2.1426e-01,  7.6214e-01,  ...,  1.0503e-01,\n",
      "           -3.2875e-01,  1.4851e-01],\n",
      "          ...,\n",
      "          [-9.5968e-01,  3.7474e-01, -3.7995e-01,  ..., -5.3994e-01,\n",
      "           -1.3506e-01, -8.4683e-02],\n",
      "          [-7.7048e-01,  4.0488e-01, -1.5944e-01,  ...,  4.8248e-02,\n",
      "            6.4608e-02,  7.3195e-02],\n",
      "          [-5.6155e-01,  6.2963e-02, -2.0233e-01,  ...,  6.3242e-01,\n",
      "           -2.9964e-01,  4.8028e-01]],\n",
      "\n",
      "         [[-3.3242e-01,  3.8360e-01, -2.6460e-01,  ..., -1.3284e-01,\n",
      "            1.0011e-01,  1.5237e-01],\n",
      "          [ 2.5161e-01, -7.9590e-02, -4.1826e-01,  ...,  2.9021e-01,\n",
      "            6.4693e-01, -3.6847e-03],\n",
      "          [-7.2333e-01, -4.0529e-01,  6.0342e-01,  ...,  2.8749e-01,\n",
      "           -7.1828e-02, -2.0649e-01],\n",
      "          ...,\n",
      "          [-8.9132e-02,  4.2637e-01, -4.8257e-01,  ..., -8.7476e-01,\n",
      "            1.5025e-02,  1.2020e-01],\n",
      "          [-3.5065e-01,  4.3955e-01, -3.3772e-01,  ..., -7.2944e-01,\n",
      "            1.7876e-01, -8.7165e-03],\n",
      "          [-6.5447e-01,  5.7953e-01, -5.9845e-01,  ..., -2.2527e-01,\n",
      "            7.2166e-02,  2.2649e-01]],\n",
      "\n",
      "         [[-1.1765e+00, -1.0791e+00, -6.3752e-01,  ..., -6.2139e-01,\n",
      "           -7.1285e-01,  6.5751e-02],\n",
      "          [-4.5631e-03, -2.9865e-01, -2.2268e-01,  ..., -1.3656e-01,\n",
      "           -6.0378e-01,  1.1800e-01],\n",
      "          [-1.1140e-01, -1.1892e-02,  7.7987e-03,  ..., -3.0117e-01,\n",
      "            3.0194e-01, -2.5939e-01],\n",
      "          ...,\n",
      "          [ 1.9670e-01,  1.8955e-01, -6.7149e-01,  ..., -6.3535e-01,\n",
      "           -4.7198e-01,  2.4423e-01],\n",
      "          [ 2.9435e-01, -4.8777e-01, -4.1071e-01,  ..., -2.2581e-01,\n",
      "            5.3428e-02,  5.3353e-01],\n",
      "          [ 1.9321e-01,  2.6070e-02, -5.9207e-01,  ..., -5.7333e-01,\n",
      "           -5.1081e-01, -5.8947e-02]]],\n",
      "\n",
      "\n",
      "        [[[-7.8602e-02, -3.2072e-01, -3.6146e-01,  ..., -9.5316e-02,\n",
      "           -2.4882e-01,  5.1134e-01],\n",
      "          [ 4.1033e-02, -1.3715e-01,  6.2516e-02,  ..., -8.0728e-02,\n",
      "           -8.1578e-02,  5.5949e-01],\n",
      "          [ 4.4600e-01, -1.3292e-02, -2.8428e-01,  ..., -3.4495e-01,\n",
      "           -2.4854e-01,  4.2393e-01],\n",
      "          ...,\n",
      "          [-1.1417e-01, -7.7129e-01, -2.9200e-01,  ...,  3.5723e-01,\n",
      "           -2.2075e-02,  6.8474e-01],\n",
      "          [ 5.3302e-02, -5.0379e-01, -4.4527e-01,  ..., -8.5963e-03,\n",
      "           -2.3234e-01,  6.0333e-01],\n",
      "          [-4.1968e-01, -1.3486e+00, -1.1934e+00,  ...,  1.2290e+00,\n",
      "            5.7471e-01,  5.0396e-01]],\n",
      "\n",
      "         [[ 3.2046e-01,  4.9326e-01,  6.2410e-01,  ..., -3.5459e-01,\n",
      "           -5.5964e-01,  4.6966e-01],\n",
      "          [ 1.6407e-01,  6.8157e-01,  4.8084e-01,  ..., -4.6754e-01,\n",
      "            1.0563e-01,  6.6984e-02],\n",
      "          [-3.3670e-03,  7.3377e-01,  4.9035e-02,  ..., -6.1428e-01,\n",
      "           -6.7607e-03, -1.9141e-01],\n",
      "          ...,\n",
      "          [ 1.1692e-01,  9.5868e-01,  3.8383e-01,  ..., -4.8771e-01,\n",
      "           -1.1058e-01,  1.0258e-01],\n",
      "          [ 3.5611e-01,  4.3385e-01,  8.4536e-01,  ..., -3.7420e-01,\n",
      "           -6.4432e-01,  9.0045e-02],\n",
      "          [ 1.4333e-01,  3.2013e-01,  8.2390e-02,  ..., -4.9031e-01,\n",
      "           -1.5368e-01,  5.5332e-01]],\n",
      "\n",
      "         [[-1.7177e-01,  4.9464e-03, -9.9688e-02,  ...,  2.8670e-01,\n",
      "           -2.2025e-01,  1.9029e-01],\n",
      "          [-1.9806e-01,  2.3635e-01,  1.8135e-01,  ...,  2.5551e-01,\n",
      "            1.4106e-01,  2.4534e-01],\n",
      "          [-1.3516e-01,  3.4474e-01, -1.0897e-01,  ..., -6.8928e-01,\n",
      "           -1.2399e-02,  3.7540e-01],\n",
      "          ...,\n",
      "          [-3.0228e-01,  1.9857e-02,  2.1353e-01,  ...,  3.5883e-01,\n",
      "           -1.3377e-01,  5.1109e-01],\n",
      "          [-3.0204e-01,  2.9528e-01,  3.4658e-01,  ..., -1.8417e-01,\n",
      "            5.0822e-02,  2.1732e-01],\n",
      "          [-3.8690e-01,  3.8115e-02, -3.9720e-02,  ...,  1.8124e-01,\n",
      "           -1.0100e-01,  2.8935e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-7.4670e-02, -5.5875e-03,  1.9029e-01,  ...,  1.3918e-01,\n",
      "            1.7480e-01,  7.3661e-01],\n",
      "          [ 6.7880e-02,  5.7915e-02, -4.3781e-01,  ...,  1.1685e-01,\n",
      "           -8.1669e-02,  3.3072e-01],\n",
      "          [-1.7683e+00,  2.0060e-01, -7.1248e-01,  ...,  1.1680e-01,\n",
      "           -2.8363e-01,  2.1862e+00],\n",
      "          ...,\n",
      "          [ 2.0741e-01, -9.2974e-02,  2.8286e-01,  ...,  3.2948e-02,\n",
      "            1.1527e-01,  8.4983e-01],\n",
      "          [ 5.8870e-01, -3.1358e-01, -6.7451e-01,  ...,  3.6658e-01,\n",
      "           -9.6220e-02, -1.4572e-01],\n",
      "          [ 4.4004e-02, -1.4830e-01,  3.5024e-01,  ..., -1.6517e-01,\n",
      "            9.7271e-02,  5.4324e-01]],\n",
      "\n",
      "         [[ 5.4462e-01, -5.7459e-01,  3.1119e-02,  ..., -2.6727e-01,\n",
      "           -5.1736e-01,  3.9662e-01],\n",
      "          [-3.6090e-01, -6.6757e-01, -1.9034e-02,  ..., -4.9054e-01,\n",
      "            4.4066e-01, -4.4940e-01],\n",
      "          [ 5.6171e-01, -5.9143e-01, -2.3828e-01,  ..., -3.3758e-01,\n",
      "           -3.4995e-01,  2.8452e-01],\n",
      "          ...,\n",
      "          [ 1.5188e-01, -4.5765e-01, -2.2215e-02,  ..., -3.5744e-01,\n",
      "           -8.1350e-01, -1.7563e-01],\n",
      "          [-1.7202e-01, -1.0399e+00, -3.2499e-01,  ..., -1.3183e-01,\n",
      "            4.3848e-01, -4.2475e-01],\n",
      "          [ 3.1674e-01, -9.7147e-01, -7.0646e-01,  ...,  1.2359e-01,\n",
      "           -6.0220e-01,  1.5796e-01]],\n",
      "\n",
      "         [[-8.6757e-03,  4.0604e-01, -4.0565e-01,  ..., -1.8928e-01,\n",
      "           -2.8094e-01, -2.6138e-01],\n",
      "          [-2.6716e-01,  6.6344e-01, -5.6559e-01,  ..., -8.6945e-02,\n",
      "           -3.0200e-02,  3.9371e-02],\n",
      "          [-1.8804e-01,  2.9957e-01, -1.0868e+00,  ..., -3.6184e-01,\n",
      "           -3.5120e-01, -4.2509e-02],\n",
      "          ...,\n",
      "          [-4.1498e-01,  5.6118e-01, -5.5429e-01,  ..., -2.2918e-01,\n",
      "            1.3820e-01, -1.2322e-01],\n",
      "          [ 1.1048e-01,  4.6936e-01, -5.0433e-01,  ..., -1.1360e-01,\n",
      "           -3.3876e-01, -3.8663e-01],\n",
      "          [ 1.1824e-01,  3.6798e-01, -5.5920e-01,  ...,  1.7623e-01,\n",
      "           -4.6912e-01, -1.9337e-01]]]])\n"
     ]
    }
   ],
   "source": [
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.0180, 0.0601, 0.0260,  ..., 0.3758, 0.1334, 0.0133],\n",
      "          [0.3908, 0.0807, 0.0795,  ..., 0.0656, 0.0289, 0.0188],\n",
      "          [0.3409, 0.0319, 0.1047,  ..., 0.0195, 0.0596, 0.1622],\n",
      "          ...,\n",
      "          [0.0573, 0.1623, 0.0544,  ..., 0.1582, 0.0978, 0.0624],\n",
      "          [0.0164, 0.0631, 0.0293,  ..., 0.0773, 0.0669, 0.1870],\n",
      "          [0.2110, 0.0840, 0.0599,  ..., 0.1923, 0.0307, 0.0273]],\n",
      "\n",
      "         [[0.0153, 0.0116, 0.0195,  ..., 0.1708, 0.1476, 0.1923],\n",
      "          [0.0374, 0.0141, 0.1279,  ..., 0.0389, 0.0975, 0.0265],\n",
      "          [0.0181, 0.0448, 0.0415,  ..., 0.1504, 0.0865, 0.0359],\n",
      "          ...,\n",
      "          [0.0938, 0.0161, 0.0439,  ..., 0.1646, 0.2964, 0.0866],\n",
      "          [0.0301, 0.0191, 0.0489,  ..., 0.1560, 0.4166, 0.1474],\n",
      "          [0.0130, 0.0220, 0.0455,  ..., 0.1164, 0.0349, 0.0251]],\n",
      "\n",
      "         [[0.1585, 0.1547, 0.0475,  ..., 0.0116, 0.1992, 0.1282],\n",
      "          [0.0722, 0.1171, 0.1464,  ..., 0.1562, 0.1852, 0.0427],\n",
      "          [0.3656, 0.1009, 0.0870,  ..., 0.1443, 0.0039, 0.1745],\n",
      "          ...,\n",
      "          [0.1781, 0.1176, 0.1237,  ..., 0.0436, 0.0457, 0.0461],\n",
      "          [0.0293, 0.0324, 0.0378,  ..., 0.0127, 0.1528, 0.5671],\n",
      "          [0.0205, 0.0271, 0.0066,  ..., 0.0541, 0.0829, 0.0748]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0674, 0.1447, 0.0614,  ..., 0.1408, 0.0622, 0.0418],\n",
      "          [0.0850, 0.0058, 0.0168,  ..., 0.2866, 0.0744, 0.0831],\n",
      "          [0.0403, 0.1013, 0.0745,  ..., 0.1138, 0.0481, 0.1796],\n",
      "          ...,\n",
      "          [0.1781, 0.1893, 0.0434,  ..., 0.0277, 0.2002, 0.0143],\n",
      "          [0.0249, 0.0547, 0.0369,  ..., 0.0607, 0.0684, 0.6659],\n",
      "          [0.0308, 0.0531, 0.0994,  ..., 0.0224, 0.0300, 0.0020]],\n",
      "\n",
      "         [[0.3551, 0.0537, 0.0336,  ..., 0.0255, 0.0558, 0.1335],\n",
      "          [0.0427, 0.2354, 0.0892,  ..., 0.0779, 0.0131, 0.0739],\n",
      "          [0.0313, 0.0454, 0.0679,  ..., 0.0916, 0.2596, 0.0181],\n",
      "          ...,\n",
      "          [0.0840, 0.2114, 0.0367,  ..., 0.0728, 0.0230, 0.1244],\n",
      "          [0.0323, 0.0954, 0.0564,  ..., 0.0589, 0.0339, 0.2172],\n",
      "          [0.0316, 0.0761, 0.0244,  ..., 0.1058, 0.1554, 0.2181]],\n",
      "\n",
      "         [[0.0213, 0.1196, 0.0624,  ..., 0.0917, 0.0746, 0.1551],\n",
      "          [0.2394, 0.0159, 0.2464,  ..., 0.1768, 0.0379, 0.0787],\n",
      "          [0.0857, 0.0233, 0.0303,  ..., 0.0066, 0.0233, 0.0529],\n",
      "          ...,\n",
      "          [0.1262, 0.0561, 0.0810,  ..., 0.0955, 0.1901, 0.1117],\n",
      "          [0.0380, 0.1666, 0.0137,  ..., 0.0412, 0.2690, 0.0999],\n",
      "          [0.6630, 0.0101, 0.0018,  ..., 0.0385, 0.0547, 0.0115]]],\n",
      "\n",
      "\n",
      "        [[[0.0492, 0.0418, 0.0296,  ..., 0.0240, 0.0345, 0.0299],\n",
      "          [0.0464, 0.0090, 0.0404,  ..., 0.1005, 0.0238, 0.3177],\n",
      "          [0.0121, 0.0779, 0.0240,  ..., 0.1205, 0.4320, 0.1175],\n",
      "          ...,\n",
      "          [0.0582, 0.1117, 0.0664,  ..., 0.0463, 0.0673, 0.0677],\n",
      "          [0.0298, 0.0735, 0.1760,  ..., 0.0270, 0.1170, 0.0251],\n",
      "          [0.0535, 0.1503, 0.1054,  ..., 0.0477, 0.0644, 0.0805]],\n",
      "\n",
      "         [[0.1101, 0.0441, 0.1039,  ..., 0.2537, 0.1368, 0.0854],\n",
      "          [0.0652, 0.1048, 0.0271,  ..., 0.0625, 0.0135, 0.5693],\n",
      "          [0.1378, 0.0135, 0.0246,  ..., 0.0358, 0.0322, 0.0763],\n",
      "          ...,\n",
      "          [0.0503, 0.2760, 0.0131,  ..., 0.0266, 0.0415, 0.0342],\n",
      "          [0.0850, 0.0809, 0.2621,  ..., 0.0647, 0.0179, 0.0441],\n",
      "          [0.0275, 0.0159, 0.1662,  ..., 0.2522, 0.2622, 0.0319]],\n",
      "\n",
      "         [[0.2243, 0.0564, 0.0249,  ..., 0.1848, 0.0348, 0.1166],\n",
      "          [0.0338, 0.0155, 0.0413,  ..., 0.3711, 0.1281, 0.2133],\n",
      "          [0.1205, 0.0650, 0.0410,  ..., 0.0655, 0.1849, 0.0958],\n",
      "          ...,\n",
      "          [0.1007, 0.0283, 0.1754,  ..., 0.0354, 0.1039, 0.0322],\n",
      "          [0.0273, 0.0364, 0.1514,  ..., 0.2430, 0.0056, 0.0186],\n",
      "          [0.1307, 0.1461, 0.0267,  ..., 0.0139, 0.0644, 0.0883]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0497, 0.0976, 0.1995,  ..., 0.0924, 0.0468, 0.0143],\n",
      "          [0.1058, 0.0734, 0.0328,  ..., 0.3537, 0.0966, 0.1342],\n",
      "          [0.0465, 0.3291, 0.1484,  ..., 0.0105, 0.0909, 0.1019],\n",
      "          ...,\n",
      "          [0.0622, 0.0290, 0.0676,  ..., 0.5618, 0.0686, 0.0370],\n",
      "          [0.1176, 0.0201, 0.1617,  ..., 0.1218, 0.0230, 0.0305],\n",
      "          [0.1329, 0.0734, 0.0970,  ..., 0.1289, 0.1481, 0.0493]],\n",
      "\n",
      "         [[0.0694, 0.0815, 0.0277,  ..., 0.0331, 0.2785, 0.0607],\n",
      "          [0.2392, 0.0503, 0.0588,  ..., 0.0837, 0.0995, 0.0608],\n",
      "          [0.1551, 0.1197, 0.0440,  ..., 0.0129, 0.1034, 0.0118],\n",
      "          ...,\n",
      "          [0.1332, 0.3311, 0.0648,  ..., 0.0341, 0.0507, 0.0159],\n",
      "          [0.1498, 0.1783, 0.0788,  ..., 0.1320, 0.0320, 0.0474],\n",
      "          [0.1833, 0.1201, 0.0216,  ..., 0.1769, 0.0809, 0.0548]],\n",
      "\n",
      "         [[0.0282, 0.0888, 0.0065,  ..., 0.2429, 0.0484, 0.0712],\n",
      "          [0.0718, 0.1492, 0.0117,  ..., 0.0873, 0.0175, 0.0662],\n",
      "          [0.0170, 0.0772, 0.4386,  ..., 0.0190, 0.0504, 0.0615],\n",
      "          ...,\n",
      "          [0.0622, 0.0347, 0.0758,  ..., 0.0895, 0.0079, 0.0603],\n",
      "          [0.0539, 0.0129, 0.1043,  ..., 0.0361, 0.0424, 0.3410],\n",
      "          [0.0750, 0.0918, 0.0465,  ..., 0.1471, 0.0887, 0.0808]]],\n",
      "\n",
      "\n",
      "        [[[0.1098, 0.1078, 0.1187,  ..., 0.1016, 0.1485, 0.0410],\n",
      "          [0.0216, 0.1040, 0.0177,  ..., 0.0599, 0.0227, 0.0190],\n",
      "          [0.2685, 0.0948, 0.4609,  ..., 0.0120, 0.0194, 0.0385],\n",
      "          ...,\n",
      "          [0.0793, 0.1351, 0.0214,  ..., 0.0145, 0.0885, 0.4300],\n",
      "          [0.1165, 0.1183, 0.1306,  ..., 0.2862, 0.0371, 0.1530],\n",
      "          [0.0235, 0.0288, 0.2751,  ..., 0.3076, 0.0412, 0.0159]],\n",
      "\n",
      "         [[0.0572, 0.0828, 0.0553,  ..., 0.0592, 0.0812, 0.0886],\n",
      "          [0.1107, 0.0793, 0.0911,  ..., 0.0350, 0.2710, 0.1198],\n",
      "          [0.0934, 0.1300, 0.2142,  ..., 0.0775, 0.0667, 0.0677],\n",
      "          ...,\n",
      "          [0.0425, 0.0577, 0.2739,  ..., 0.0307, 0.0169, 0.1236],\n",
      "          [0.0651, 0.0851, 0.1711,  ..., 0.5491, 0.0163, 0.0108],\n",
      "          [0.1495, 0.0238, 0.0349,  ..., 0.0966, 0.0363, 0.1772]],\n",
      "\n",
      "         [[0.0063, 0.3199, 0.0706,  ..., 0.2376, 0.0750, 0.0300],\n",
      "          [0.2314, 0.1314, 0.2063,  ..., 0.1823, 0.0302, 0.0179],\n",
      "          [0.0626, 0.0314, 0.2659,  ..., 0.0424, 0.1785, 0.0457],\n",
      "          ...,\n",
      "          [0.0129, 0.0688, 0.0094,  ..., 0.0402, 0.6924, 0.0766],\n",
      "          [0.4068, 0.0766, 0.0504,  ..., 0.0572, 0.0832, 0.0551],\n",
      "          [0.3015, 0.0925, 0.0768,  ..., 0.1096, 0.0310, 0.0906]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0882, 0.1289, 0.0735,  ..., 0.0402, 0.0089, 0.1673],\n",
      "          [0.1255, 0.0517, 0.0563,  ..., 0.0393, 0.1492, 0.0382],\n",
      "          [0.0258, 0.3486, 0.1235,  ..., 0.0597, 0.0092, 0.1368],\n",
      "          ...,\n",
      "          [0.1521, 0.1698, 0.0352,  ..., 0.0628, 0.1210, 0.1627],\n",
      "          [0.1328, 0.2829, 0.0270,  ..., 0.0635, 0.1892, 0.1300],\n",
      "          [0.0392, 0.0727, 0.1726,  ..., 0.1099, 0.0835, 0.0176]],\n",
      "\n",
      "         [[0.0818, 0.1122, 0.0910,  ..., 0.1233, 0.0253, 0.1720],\n",
      "          [0.2198, 0.1006, 0.0270,  ..., 0.0296, 0.0276, 0.4803],\n",
      "          [0.1236, 0.1021, 0.0835,  ..., 0.1357, 0.1487, 0.1172],\n",
      "          ...,\n",
      "          [0.1016, 0.1540, 0.0581,  ..., 0.0180, 0.1110, 0.0229],\n",
      "          [0.1517, 0.0828, 0.1610,  ..., 0.0976, 0.2230, 0.0190],\n",
      "          [0.1258, 0.0153, 0.0249,  ..., 0.1598, 0.1343, 0.1787]],\n",
      "\n",
      "         [[0.0700, 0.0685, 0.0725,  ..., 0.1497, 0.1041, 0.1879],\n",
      "          [0.0309, 0.0537, 0.0315,  ..., 0.1449, 0.0454, 0.1012],\n",
      "          [0.0725, 0.0352, 0.6416,  ..., 0.0484, 0.0724, 0.0163],\n",
      "          ...,\n",
      "          [0.2265, 0.0093, 0.1341,  ..., 0.0832, 0.1150, 0.1188],\n",
      "          [0.0417, 0.2668, 0.0731,  ..., 0.0419, 0.0115, 0.0537],\n",
      "          [0.1269, 0.0756, 0.0211,  ..., 0.0625, 0.1818, 0.0652]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.1426, 0.1541, 0.0219,  ..., 0.0704, 0.0088, 0.0358],\n",
      "          [0.0350, 0.1001, 0.2124,  ..., 0.0463, 0.1100, 0.0318],\n",
      "          [0.0283, 0.0241, 0.1580,  ..., 0.0373, 0.0367, 0.0980],\n",
      "          ...,\n",
      "          [0.0610, 0.0847, 0.0924,  ..., 0.0948, 0.1316, 0.2517],\n",
      "          [0.0513, 0.0954, 0.0725,  ..., 0.1627, 0.2312, 0.0473],\n",
      "          [0.2978, 0.0421, 0.0434,  ..., 0.0726, 0.1953, 0.0087]],\n",
      "\n",
      "         [[0.4307, 0.0096, 0.0683,  ..., 0.0575, 0.0624, 0.0324],\n",
      "          [0.0844, 0.0340, 0.0455,  ..., 0.1076, 0.0288, 0.0797],\n",
      "          [0.1846, 0.1171, 0.1856,  ..., 0.1629, 0.0439, 0.0595],\n",
      "          ...,\n",
      "          [0.5137, 0.0302, 0.0059,  ..., 0.0165, 0.0345, 0.1555],\n",
      "          [0.3279, 0.0781, 0.0561,  ..., 0.0400, 0.0301, 0.2533],\n",
      "          [0.0917, 0.1608, 0.1750,  ..., 0.0507, 0.0735, 0.1368]],\n",
      "\n",
      "         [[0.3877, 0.3131, 0.0325,  ..., 0.0017, 0.0329, 0.0335],\n",
      "          [0.2029, 0.0373, 0.1005,  ..., 0.1536, 0.1372, 0.0331],\n",
      "          [0.1069, 0.0369, 0.0478,  ..., 0.0729, 0.0162, 0.0180],\n",
      "          ...,\n",
      "          [0.0500, 0.1099, 0.0827,  ..., 0.2372, 0.0582, 0.1307],\n",
      "          [0.0708, 0.0638, 0.0849,  ..., 0.1010, 0.0375, 0.1568],\n",
      "          [0.0210, 0.0018, 0.0376,  ..., 0.2671, 0.3680, 0.1841]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0470, 0.1617, 0.0274,  ..., 0.0074, 0.0390, 0.2495],\n",
      "          [0.0418, 0.0636, 0.0386,  ..., 0.1869, 0.0105, 0.0430],\n",
      "          [0.2790, 0.0862, 0.0533,  ..., 0.0693, 0.0979, 0.0919],\n",
      "          ...,\n",
      "          [0.0555, 0.1660, 0.0169,  ..., 0.0203, 0.0397, 0.0446],\n",
      "          [0.0820, 0.0227, 0.0179,  ..., 0.0339, 0.2495, 0.0801],\n",
      "          [0.0477, 0.1988, 0.0364,  ..., 0.0321, 0.3356, 0.0179]],\n",
      "\n",
      "         [[0.1260, 0.1032, 0.0214,  ..., 0.0323, 0.1294, 0.0242],\n",
      "          [0.0520, 0.4773, 0.0891,  ..., 0.0501, 0.0632, 0.0762],\n",
      "          [0.1367, 0.1475, 0.1298,  ..., 0.1286, 0.0748, 0.0280],\n",
      "          ...,\n",
      "          [0.2629, 0.0451, 0.2190,  ..., 0.1020, 0.0257, 0.1475],\n",
      "          [0.1329, 0.0401, 0.0385,  ..., 0.1030, 0.1104, 0.0187],\n",
      "          [0.0886, 0.0966, 0.0275,  ..., 0.1190, 0.1123, 0.0552]],\n",
      "\n",
      "         [[0.0221, 0.2848, 0.0391,  ..., 0.0508, 0.3227, 0.0132],\n",
      "          [0.1446, 0.1239, 0.0521,  ..., 0.0469, 0.0460, 0.0873],\n",
      "          [0.1124, 0.1146, 0.0277,  ..., 0.0636, 0.1012, 0.0756],\n",
      "          ...,\n",
      "          [0.0369, 0.0396, 0.0247,  ..., 0.1494, 0.2262, 0.2411],\n",
      "          [0.0421, 0.0286, 0.0475,  ..., 0.1932, 0.0288, 0.0467],\n",
      "          [0.0154, 0.2641, 0.0218,  ..., 0.3280, 0.2374, 0.0116]]],\n",
      "\n",
      "\n",
      "        [[[0.0271, 0.0269, 0.1728,  ..., 0.0386, 0.0527, 0.0935],\n",
      "          [0.1299, 0.0404, 0.0244,  ..., 0.2647, 0.1125, 0.0556],\n",
      "          [0.0953, 0.0442, 0.0722,  ..., 0.0570, 0.0212, 0.0934],\n",
      "          ...,\n",
      "          [0.0841, 0.3293, 0.0960,  ..., 0.0253, 0.1281, 0.0444],\n",
      "          [0.2942, 0.1744, 0.0093,  ..., 0.1262, 0.0707, 0.0319],\n",
      "          [0.0154, 0.1283, 0.0654,  ..., 0.0952, 0.2904, 0.0866]],\n",
      "\n",
      "         [[0.0194, 0.0765, 0.1028,  ..., 0.2603, 0.0193, 0.1557],\n",
      "          [0.0187, 0.0366, 0.1536,  ..., 0.0611, 0.0108, 0.1527],\n",
      "          [0.0736, 0.1503, 0.1226,  ..., 0.0513, 0.2090, 0.0320],\n",
      "          ...,\n",
      "          [0.0184, 0.0566, 0.1694,  ..., 0.1474, 0.2732, 0.0171],\n",
      "          [0.3070, 0.0260, 0.0455,  ..., 0.0148, 0.3124, 0.0637],\n",
      "          [0.1568, 0.0712, 0.0431,  ..., 0.0408, 0.0760, 0.0348]],\n",
      "\n",
      "         [[0.0475, 0.0670, 0.0779,  ..., 0.0232, 0.3876, 0.0567],\n",
      "          [0.1764, 0.0632, 0.0043,  ..., 0.2662, 0.2292, 0.0115],\n",
      "          [0.0184, 0.0915, 0.0644,  ..., 0.1425, 0.0496, 0.0530],\n",
      "          ...,\n",
      "          [0.0184, 0.1122, 0.0541,  ..., 0.0276, 0.1092, 0.0349],\n",
      "          [0.2243, 0.0341, 0.0262,  ..., 0.0623, 0.1884, 0.0962],\n",
      "          [0.1000, 0.0753, 0.0393,  ..., 0.1729, 0.0510, 0.0537]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0222, 0.1101, 0.0793,  ..., 0.0699, 0.2203, 0.0798],\n",
      "          [0.0334, 0.1026, 0.2944,  ..., 0.0079, 0.0469, 0.0017],\n",
      "          [0.0275, 0.0225, 0.0332,  ..., 0.0323, 0.0583, 0.4778],\n",
      "          ...,\n",
      "          [0.0943, 0.0313, 0.1447,  ..., 0.2799, 0.0706, 0.0465],\n",
      "          [0.0948, 0.0492, 0.0660,  ..., 0.0383, 0.0723, 0.0797],\n",
      "          [0.0495, 0.1453, 0.1667,  ..., 0.0189, 0.0214, 0.0170]],\n",
      "\n",
      "         [[0.0830, 0.1049, 0.0401,  ..., 0.2221, 0.0445, 0.0345],\n",
      "          [0.0539, 0.3502, 0.0889,  ..., 0.0507, 0.2001, 0.0324],\n",
      "          [0.1873, 0.0052, 0.0082,  ..., 0.0161, 0.5662, 0.0433],\n",
      "          ...,\n",
      "          [0.0896, 0.1446, 0.0079,  ..., 0.0649, 0.2553, 0.0357],\n",
      "          [0.0970, 0.0576, 0.0540,  ..., 0.0309, 0.1652, 0.1105],\n",
      "          [0.0771, 0.0357, 0.0902,  ..., 0.0206, 0.0029, 0.5580]],\n",
      "\n",
      "         [[0.2576, 0.0526, 0.0671,  ..., 0.0716, 0.0395, 0.1167],\n",
      "          [0.0283, 0.0634, 0.0748,  ..., 0.0148, 0.0681, 0.0397],\n",
      "          [0.2895, 0.0944, 0.0212,  ..., 0.0422, 0.0138, 0.0302],\n",
      "          ...,\n",
      "          [0.0748, 0.0287, 0.1717,  ..., 0.0379, 0.1582, 0.0562],\n",
      "          [0.0238, 0.0707, 0.0108,  ..., 0.0285, 0.3062, 0.2417],\n",
      "          [0.1744, 0.0389, 0.0391,  ..., 0.1119, 0.0966, 0.0307]]],\n",
      "\n",
      "\n",
      "        [[[0.2146, 0.0614, 0.0335,  ..., 0.0343, 0.2316, 0.0136],\n",
      "          [0.0067, 0.0115, 0.0237,  ..., 0.2094, 0.0015, 0.0213],\n",
      "          [0.4561, 0.0843, 0.0585,  ..., 0.0277, 0.0679, 0.0789],\n",
      "          ...,\n",
      "          [0.1972, 0.0735, 0.1557,  ..., 0.0404, 0.0178, 0.1443],\n",
      "          [0.0245, 0.0956, 0.0688,  ..., 0.2179, 0.0818, 0.0668],\n",
      "          [0.2538, 0.1715, 0.0993,  ..., 0.0310, 0.0643, 0.1142]],\n",
      "\n",
      "         [[0.2071, 0.0065, 0.0670,  ..., 0.0496, 0.1428, 0.0777],\n",
      "          [0.0135, 0.0527, 0.0302,  ..., 0.0067, 0.0944, 0.0361],\n",
      "          [0.0454, 0.2344, 0.2695,  ..., 0.1186, 0.1153, 0.0420],\n",
      "          ...,\n",
      "          [0.1289, 0.0806, 0.1160,  ..., 0.0589, 0.2998, 0.0559],\n",
      "          [0.0509, 0.1310, 0.0383,  ..., 0.0858, 0.1748, 0.0630],\n",
      "          [0.0710, 0.0631, 0.0502,  ..., 0.0578, 0.2408, 0.1101]],\n",
      "\n",
      "         [[0.0486, 0.0282, 0.0469,  ..., 0.5666, 0.0293, 0.0477],\n",
      "          [0.0110, 0.1612, 0.0695,  ..., 0.0653, 0.0852, 0.0313],\n",
      "          [0.0743, 0.2208, 0.0201,  ..., 0.0620, 0.0380, 0.0264],\n",
      "          ...,\n",
      "          [0.1328, 0.0604, 0.0786,  ..., 0.0519, 0.2531, 0.1054],\n",
      "          [0.0298, 0.0292, 0.0476,  ..., 0.1435, 0.0448, 0.0508],\n",
      "          [0.0958, 0.0589, 0.0706,  ..., 0.4174, 0.0674, 0.1023]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.2508, 0.0261, 0.0617,  ..., 0.0770, 0.0702, 0.1751],\n",
      "          [0.0562, 0.1205, 0.0139,  ..., 0.0287, 0.0833, 0.0682],\n",
      "          [0.1043, 0.1349, 0.0783,  ..., 0.1463, 0.1027, 0.1722],\n",
      "          ...,\n",
      "          [0.0636, 0.1558, 0.1989,  ..., 0.2701, 0.0265, 0.0815],\n",
      "          [0.0263, 0.2056, 0.0327,  ..., 0.1342, 0.0308, 0.0325],\n",
      "          [0.0786, 0.2393, 0.0189,  ..., 0.0939, 0.0560, 0.1235]],\n",
      "\n",
      "         [[0.1218, 0.0235, 0.0535,  ..., 0.0915, 0.2435, 0.0913],\n",
      "          [0.0602, 0.1750, 0.0981,  ..., 0.2112, 0.0276, 0.0402],\n",
      "          [0.4086, 0.0642, 0.0288,  ..., 0.0201, 0.2383, 0.0632],\n",
      "          ...,\n",
      "          [0.0525, 0.0224, 0.3096,  ..., 0.1063, 0.0307, 0.0366],\n",
      "          [0.0387, 0.4206, 0.1334,  ..., 0.0469, 0.0168, 0.0332],\n",
      "          [0.0882, 0.1884, 0.0972,  ..., 0.0406, 0.0784, 0.1992]],\n",
      "\n",
      "         [[0.0324, 0.0560, 0.0963,  ..., 0.0431, 0.0267, 0.0443],\n",
      "          [0.0893, 0.0777, 0.0088,  ..., 0.0454, 0.1362, 0.1075],\n",
      "          [0.1275, 0.1861, 0.2640,  ..., 0.0833, 0.0962, 0.0415],\n",
      "          ...,\n",
      "          [0.0547, 0.2598, 0.2708,  ..., 0.0376, 0.0249, 0.1221],\n",
      "          [0.3385, 0.1098, 0.0345,  ..., 0.0092, 0.0901, 0.0020],\n",
      "          [0.0540, 0.0405, 0.0620,  ..., 0.1908, 0.2293, 0.1006]]]])\n"
     ]
    }
   ],
   "source": [
    "print(att_scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
